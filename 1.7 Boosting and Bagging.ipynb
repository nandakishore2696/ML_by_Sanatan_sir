{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "\n",
    "# Airline Customers Tweets\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts() # MultiClass Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(Airline, Tweet) --> Sentiment ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'].isna().sum() # No NULL Values as the sum is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].isna().sum() # --> Output with no NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Virgin America\n",
       "1        Virgin America\n",
       "2        Virgin America\n",
       "3        Virgin America\n",
       "4        Virgin America\n",
       "              ...      \n",
       "14635          American\n",
       "14636          American\n",
       "14637          American\n",
       "14638          American\n",
       "14639          American\n",
       "Name: airline, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'] # You need to encode this Nominal feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8751, 8480, 4347, ..., 5381, 3099, 5840])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = np.random.choice(range(df.shape[0]), 2500) # Randomly selecting 2500 indexes\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8751         Delta\n",
       "8480         Delta\n",
       "4347     Southwest\n",
       "13424     American\n",
       "7512         Delta\n",
       "           ...    \n",
       "1470        United\n",
       "1653        United\n",
       "5381     Southwest\n",
       "3099        United\n",
       "5840     Southwest\n",
       "Name: airline, Length: 2500, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[indexes, 'airline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>US Airways</th>\n",
       "      <th>United</th>\n",
       "      <th>Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13424</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       American  Delta  Southwest  US Airways  United  Virgin America\n",
       "8751          0      1          0           0       0               0\n",
       "8480          0      1          0           0       0               0\n",
       "4347          0      0          1           0       0               0\n",
       "13424         1      0          0           0       0               0\n",
       "7512          0      1          0           0       0               0\n",
       "...         ...    ...        ...         ...     ...             ...\n",
       "1470          0      0          0           0       1               0\n",
       "1653          0      0          0           0       1               0\n",
       "5381          0      0          1           0       0               0\n",
       "3099          0      0          0           0       1               0\n",
       "5840          0      0          1           0       0               0\n",
       "\n",
       "[2500 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df.loc[indexes, 'airline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>US Airways</th>\n",
       "      <th>United</th>\n",
       "      <th>Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13424</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       American  Delta  Southwest  US Airways  United  Virgin America\n",
       "8751          0      1          0           0       0               0\n",
       "8480          0      1          0           0       0               0\n",
       "4347          0      0          1           0       0               0\n",
       "13424         1      0          0           0       0               0\n",
       "7512          0      1          0           0       0               0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df = pd.get_dummies(df.loc[indexes, 'airline'])\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      @VirginAmerica What @dhepburn said.\n",
       "1        @VirginAmerica plus you've added commercials t...\n",
       "2        @VirginAmerica I didn't today... Must mean I n...\n",
       "3        @VirginAmerica it's really aggressive to blast...\n",
       "4        @VirginAmerica and it's a really big bad thing...\n",
       "                               ...                        \n",
       "14635    @AmericanAir thank you we got on a different f...\n",
       "14636    @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637    @AmericanAir Please bring American Airlines to...\n",
       "14638    @AmericanAir you have my money, you change my ...\n",
       "14639    @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "Name: text, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8751     @jetblue i have the emails that they are on th...\n",
       "8480                @jetblue the best airline in the world\n",
       "4347     @southwestair  thanks southwest for saving our...\n",
       "13424    @americanair  i have still not talked to anyon...\n",
       "7512     @jetblue i know, but i wanted to pass it along...\n",
       "                               ...                        \n",
       "1470     @united it was delivered! thank you for making...\n",
       "1653     @united when i click that link it wants my fli...\n",
       "5381     @southwestair - i get that weather delays are ...\n",
       "3099     @united another unfortunate case of bad luck, ...\n",
       "5840     @southwestair you're going to compensate us fo...\n",
       "Name: text, Length: 2500, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[indexes, 'text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "# The Input to this CountVectorizer is a collection of strings, an array of strings, a list of strings, a Series of strings.... \n",
    "cv.fit(df.loc[indexes, 'text'].str.lower()) # It will compute all the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5045"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jetblue': 2547,\n",
       " 'have': 2231,\n",
       " 'the': 4420,\n",
       " 'emails': 1678,\n",
       " 'that': 4417,\n",
       " 'they': 4438,\n",
       " 'are': 648,\n",
       " 'on': 3231,\n",
       " 'their': 4425,\n",
       " 'way': 4849,\n",
       " 'best': 847,\n",
       " 'airline': 505,\n",
       " 'in': 2394,\n",
       " 'world': 4957,\n",
       " 'southwestair': 4160,\n",
       " 'thanks': 4413,\n",
       " 'southwest': 4159,\n",
       " 'for': 1988,\n",
       " 'saving': 3922,\n",
       " 'our': 3281,\n",
       " 'trip': 4558,\n",
       " 'my': 3053,\n",
       " 'sweetheart': 4341,\n",
       " 'isn': 2494,\n",
       " 'going': 2138,\n",
       " 'to': 4495,\n",
       " 'miss': 2987,\n",
       " 'seeing': 3970,\n",
       " 'altonbrownlive': 548,\n",
       " 'all': 529,\n",
       " 'sohappy': 4123,\n",
       " 'americanair': 565,\n",
       " 'still': 4249,\n",
       " 'not': 3150,\n",
       " 'talked': 4373,\n",
       " 'anyone': 616,\n",
       " 'you': 5022,\n",
       " 'guys': 2190,\n",
       " 'should': 4034,\n",
       " 'be': 812,\n",
       " 'prepared': 3521,\n",
       " 'these': 4437,\n",
       " 'situations': 4079,\n",
       " 'how': 2331,\n",
       " 'is': 2490,\n",
       " 'this': 4446,\n",
       " 'good': 2144,\n",
       " 'service': 4000,\n",
       " 'am': 554,\n",
       " 'so': 4119,\n",
       " 'mad': 2835,\n",
       " 'know': 2634,\n",
       " 'but': 982,\n",
       " 'wanted': 4828,\n",
       " 'pass': 3344,\n",
       " 'it': 2503,\n",
       " 'along': 539,\n",
       " 't5': 4359,\n",
       " 'experience': 1786,\n",
       " 'esp': 1733,\n",
       " 'someone': 4133,\n",
       " 'who': 4903,\n",
       " 'flies': 1932,\n",
       " 'times': 4481,\n",
       " 'month': 3016,\n",
       " 'why': 4907,\n",
       " 'we': 4856,\n",
       " 'delayed': 1447,\n",
       " 'flight': 1933,\n",
       " '1601': 72,\n",
       " 'was': 4836,\n",
       " '3rd': 233,\n",
       " 'cancelled': 1021,\n",
       " 'flightlation': 1943,\n",
       " 'days': 1412,\n",
       " 'due': 1632,\n",
       " 'weather': 4859,\n",
       " 'nashville': 3069,\n",
       " 'trips': 4560,\n",
       " 'airport': 511,\n",
       " 'each': 1643,\n",
       " 'time': 4478,\n",
       " 'communicated': 1213,\n",
       " 'late': 2671,\n",
       " 'by': 987,\n",
       " 'sw': 4334,\n",
       " 'usairways': 4732,\n",
       " '850': 372,\n",
       " 'rude': 3872,\n",
       " 'awful': 742,\n",
       " 'united': 4674,\n",
       " 'or': 3257,\n",
       " 'flysaa': 1972,\n",
       " 'has': 2223,\n",
       " 'lost': 2790,\n",
       " 'baggage': 775,\n",
       " 'heard': 2244,\n",
       " 'different': 1513,\n",
       " 'things': 4442,\n",
       " 'from': 2036,\n",
       " 'employees': 1690,\n",
       " 'of': 3202,\n",
       " 'said': 3896,\n",
       " 'nothing': 3157,\n",
       " 'get': 2103,\n",
       " 'sunday': 4309,\n",
       " 'and': 584,\n",
       " 'ok': 3222,\n",
       " 'monday': 3011,\n",
       " 're': 3656,\n",
       " 'busy': 981,\n",
       " 'crazy': 1344,\n",
       " 'can': 1017,\n",
       " 'dm': 1569,\n",
       " 'me': 2899,\n",
       " 'amp': 575,\n",
       " 'add': 457,\n",
       " 'upgrade': 4714,\n",
       " 'list': 2732,\n",
       " 'flt': 1960,\n",
       " 'tonight': 4507,\n",
       " 'hi': 2266,\n",
       " 'there': 4435,\n",
       " 'check': 1101,\n",
       " 'track': 4530,\n",
       " 'will': 4915,\n",
       " 'arrive': 666,\n",
       " 'depart': 1463,\n",
       " 'received': 3682,\n",
       " 'luggage': 2818,\n",
       " 'also': 543,\n",
       " 'looked': 2779,\n",
       " 'left': 2693,\n",
       " 'snow': 4114,\n",
       " 'when': 4892,\n",
       " 'arrived': 667,\n",
       " 'asking': 679,\n",
       " '50': 281,\n",
       " 'people': 3377,\n",
       " 'refunded': 3715,\n",
       " 'sure': 4324,\n",
       " 'expected': 1781,\n",
       " 'here': 2261,\n",
       " 'http': 2338,\n",
       " 'co': 1180,\n",
       " 'bnflhpxtmw': 893,\n",
       " 'doesn': 1576,\n",
       " 'allow': 532,\n",
       " 'conversations': 1296,\n",
       " 'between': 856,\n",
       " 'upset': 4719,\n",
       " 'customers': 1377,\n",
       " 'customer': 1376,\n",
       " 'worstcustomerserviceever': 4968,\n",
       " 'everytime': 1754,\n",
       " 'fly': 1963,\n",
       " 'ur': 4720,\n",
       " 'hate': 2227,\n",
       " 'even': 1745,\n",
       " 'more': 3021,\n",
       " 'terrible': 4401,\n",
       " '1071': 24,\n",
       " 'hey': 2263,\n",
       " 'flying': 1969,\n",
       " 'tampa': 4375,\n",
       " 'denver': 1462,\n",
       " 'today': 4497,\n",
       " 'want': 4827,\n",
       " 'if': 2371,\n",
       " 'tv': 4588,\n",
       " 'seats': 3959,\n",
       " 'like': 2721,\n",
       " 'aa1401': 404,\n",
       " 'landed': 2660,\n",
       " 'at': 696,\n",
       " '55pm': 299,\n",
       " 'miami': 2950,\n",
       " 'waiting': 4811,\n",
       " 'gate': 2088,\n",
       " 'your': 5025,\n",
       " 'team': 4388,\n",
       " 'help': 2254,\n",
       " 'us': 4723,\n",
       " 'out': 3285,\n",
       " 'been': 827,\n",
       " 'solved': 4128,\n",
       " 'finally': 1899,\n",
       " 'picked': 3417,\n",
       " 'up': 4708,\n",
       " 'second': 3963,\n",
       " 'called': 1007,\n",
       " 'response': 3801,\n",
       " 'jh': 2555,\n",
       " '21': 132,\n",
       " 'dulles': 1634,\n",
       " 'works': 4956,\n",
       " 'officially': 3214,\n",
       " 'hold': 2281,\n",
       " 'hours': 2326,\n",
       " 'son': 4138,\n",
       " 'his': 2276,\n",
       " 'tablet': 4361,\n",
       " 'plane': 3444,\n",
       " 'country': 1328,\n",
       " 'call': 1005,\n",
       " 'easily': 1653,\n",
       " 'an': 578,\n",
       " 'email': 1676,\n",
       " 'contact': 1280,\n",
       " 'never': 3097,\n",
       " 'got': 2150,\n",
       " 'wife': 4910,\n",
       " 'her': 2259,\n",
       " 'destination': 1485,\n",
       " 'expect': 1779,\n",
       " '75': 346,\n",
       " '00': 0,\n",
       " 'goodwill': 2146,\n",
       " 'credit': 1347,\n",
       " 'make': 2849,\n",
       " 'everything': 1753,\n",
       " 'hunky': 2348,\n",
       " 'dory': 1597,\n",
       " 'blew': 883,\n",
       " 'what': 4885,\n",
       " 'with': 4929,\n",
       " 'ua': 4604,\n",
       " '236': 145,\n",
       " 'outbound': 3287,\n",
       " 'last': 2670,\n",
       " 'thurs': 4464,\n",
       " '4hrs': 276,\n",
       " 'long': 2775,\n",
       " 'delay': 1446,\n",
       " 'worst2unitedflightsever': 4965,\n",
       " 'emailed': 1677,\n",
       " 'several': 4008,\n",
       " 'hand': 2197,\n",
       " 'wrote': 4981,\n",
       " 'letter': 2706,\n",
       " 'went': 4876,\n",
       " 'please': 3459,\n",
       " 'fix': 1917,\n",
       " 'abc7newsbayarea': 416,\n",
       " 'sooo': 4143,\n",
       " 'earlier': 1645,\n",
       " 'couldnt': 1323,\n",
       " 'school': 3940,\n",
       " 'now': 3168,\n",
       " 'do': 1572,\n",
       " 'formally': 2003,\n",
       " 'complain': 1232,\n",
       " 'about': 421,\n",
       " 'handler': 2201,\n",
       " 'misconnected': 2980,\n",
       " 'denied': 1461,\n",
       " 'boarding': 897,\n",
       " 'bag': 774,\n",
       " 'treated': 4552,\n",
       " 'poorly': 3480,\n",
       " 'life': 2717,\n",
       " 'as': 672,\n",
       " 'military': 2965,\n",
       " 'family': 1833,\n",
       " 'alot': 540,\n",
       " 'point': 3470,\n",
       " 'don': 1584,\n",
       " 'need': 3084,\n",
       " 'sorry': 4147,\n",
       " 'revers': 3822,\n",
       " 'agt': 495,\n",
       " 'pick': 3416,\n",
       " 'maybe': 2887,\n",
       " '11': 28,\n",
       " '30': 187,\n",
       " 'ever': 1749,\n",
       " 'again': 486,\n",
       " 'booking': 907,\n",
       " 'problems': 3551,\n",
       " 'any': 613,\n",
       " 'affiliate': 479,\n",
       " 'chance': 1076,\n",
       " 'crew': 1349,\n",
       " 'into': 2470,\n",
       " 'btv': 953,\n",
       " 'nite': 3122,\n",
       " 'todays': 4498,\n",
       " 'connection': 1267,\n",
       " 'cun': 1368,\n",
       " 'play': 3454,\n",
       " 'hotel': 2318,\n",
       " 'ewr': 1757,\n",
       " 'rules': 3877,\n",
       " 'patient': 3359,\n",
       " 'luxurious': 2825,\n",
       " 'middle': 2953,\n",
       " 'seat': 3955,\n",
       " 'next': 3110,\n",
       " 'think': 4443,\n",
       " 'll': 2743,\n",
       " 'testing': 4404,\n",
       " 'those': 4450,\n",
       " 'waters': 4848,\n",
       " 'own': 3308,\n",
       " 'dime': 1515,\n",
       " 'wannaa': 4826,\n",
       " 'go': 2133,\n",
       " 'vegas': 4764,\n",
       " 'show': 4041,\n",
       " 'bad': 766,\n",
       " 'id': 2366,\n",
       " 'doo': 1593,\n",
       " 'anything': 617,\n",
       " 'destinationdragons': 1486,\n",
       " 'cheerupdates': 1110,\n",
       " 'saying': 3926,\n",
       " 'center': 1067,\n",
       " 'understaffed': 4650,\n",
       " 'item': 2505,\n",
       " 'bos': 912,\n",
       " 'phl': 3405,\n",
       " 'friday': 2031,\n",
       " 've': 4763,\n",
       " 'airways': 515,\n",
       " 'msgs': 3037,\n",
       " 'no': 3126,\n",
       " 'return': 3817,\n",
       " 'dallas': 1393,\n",
       " 'incoming': 2410,\n",
       " 'looking': 2780,\n",
       " 'scheduled': 3938,\n",
       " '10': 14,\n",
       " 'wondering': 4943,\n",
       " 'stuck': 4285,\n",
       " 'st': 4207,\n",
       " 'louis': 2795,\n",
       " 'instead': 2453,\n",
       " 'dates': 1408,\n",
       " 'past': 3354,\n",
       " 'august': 715,\n",
       " '2015': 119,\n",
       " 'nope': 3141,\n",
       " 'sitting': 4076,\n",
       " 'splitting': 4188,\n",
       " 'flights': 1951,\n",
       " 'quadruples': 3616,\n",
       " 'price': 3532,\n",
       " 'replying': 3762,\n",
       " 'sen': 3985,\n",
       " 'conf': 1252,\n",
       " 'love': 2798,\n",
       " 'aviation': 731,\n",
       " '18th': 103,\n",
       " 'swa': 4335,\n",
       " 'day': 1411,\n",
       " 'sent': 3989,\n",
       " 'suggestion': 4302,\n",
       " 'comments': 1209,\n",
       " 'via': 4775,\n",
       " 'link': 2729,\n",
       " 'provided': 3578,\n",
       " 'speak': 4174,\n",
       " 'agent': 489,\n",
       " '8pm': 383,\n",
       " 'had': 2193,\n",
       " 'unfortunate': 4664,\n",
       " 'incident': 2402,\n",
       " 'discrimination': 1540,\n",
       " 'home': 2288,\n",
       " 'off': 3204,\n",
       " 'ground': 2175,\n",
       " 'pastmypatienceexpirationdate': 3355,\n",
       " 'honesty': 2292,\n",
       " 'always': 549,\n",
       " 'policy': 3476,\n",
       " '4524': 261,\n",
       " 'deadhead': 1421,\n",
       " 'lets': 2704,\n",
       " '150': 59,\n",
       " 'paying': 3363,\n",
       " 'wait': 4809,\n",
       " 'great': 2162,\n",
       " 'follow': 1980,\n",
       " 'flightled': 1945,\n",
       " 'rebook': 3677,\n",
       " 'online': 3237,\n",
       " 'would': 4970,\n",
       " 'info': 2438,\n",
       " 'thank': 4411,\n",
       " 'regarding': 3720,\n",
       " 'kphl': 2641,\n",
       " 'much': 3043,\n",
       " 'appreciated': 637,\n",
       " 'yet': 5018,\n",
       " 'another': 601,\n",
       " 'missed': 2988,\n",
       " 'attitude': 710,\n",
       " 'wow': 4975,\n",
       " 'making': 2853,\n",
       " 'dreams': 1618,\n",
       " 'come': 1198,\n",
       " 'true': 4565,\n",
       " 'scavenger': 3935,\n",
       " 'hunt': 2349,\n",
       " 'win': 4917,\n",
       " 'see': 3969,\n",
       " 'imagine': 2379,\n",
       " 'dragons': 1612,\n",
       " 'already': 541,\n",
       " 'care': 1037,\n",
       " '1891': 100,\n",
       " 'though': 4451,\n",
       " 'ow': 3306,\n",
       " 'caused': 1059,\n",
       " 'failure': 1821,\n",
       " 'only': 3238,\n",
       " 'fluctuated': 1962,\n",
       " 'because': 823,\n",
       " 'aa': 401,\n",
       " 'took': 4510,\n",
       " 'hrs': 2337,\n",
       " 'back': 763,\n",
       " 'ended': 1697,\n",
       " 'extra': 1801,\n",
       " 'above': 422,\n",
       " 'statement': 4227,\n",
       " 'say': 3925,\n",
       " 'right': 3832,\n",
       " 'sincerely': 4066,\n",
       " 'bestairline': 848,\n",
       " 'trying': 4574,\n",
       " 'look': 2778,\n",
       " 'website': 4861,\n",
       " 'says': 3927,\n",
       " 'charleston': 1091,\n",
       " 'nc': 3079,\n",
       " 'its': 2512,\n",
       " 'actually': 454,\n",
       " 'sc': 3930,\n",
       " 'could': 1321,\n",
       " 'md80': 2896,\n",
       " 'dc10': 1415,\n",
       " 'happy': 2216,\n",
       " 'live': 2737,\n",
       " '2954': 167,\n",
       " 'grand': 2157,\n",
       " 'junction': 2579,\n",
       " 'amazingflightcrew': 558,\n",
       " 'frankly': 2021,\n",
       " 'standard': 4213,\n",
       " 'sop': 4145,\n",
       " 'open': 3246,\n",
       " 'kiosks': 2627,\n",
       " 'priority': 3544,\n",
       " 'line': 2727,\n",
       " 'main': 2845,\n",
       " '80': 360,\n",
       " '100': 15,\n",
       " 'ppl': 3498,\n",
       " 'tickets': 4471,\n",
       " 'event': 1748,\n",
       " 'stoked': 4258,\n",
       " 'one': 3234,\n",
       " 'better': 854,\n",
       " 'than': 4410,\n",
       " 'them': 4426,\n",
       " 'onelove': 3235,\n",
       " 'won': 4940,\n",
       " 'deliver': 1455,\n",
       " 'almost': 537,\n",
       " 'two': 4597,\n",
       " 'holding': 2283,\n",
       " 'phone': 3409,\n",
       " 'over': 3293,\n",
       " 'betty': 855,\n",
       " 'working': 4954,\n",
       " 'ilm': 2376,\n",
       " 'lovely': 2803,\n",
       " 'agents': 490,\n",
       " 'clt': 1172,\n",
       " 'helping': 2257,\n",
       " 'phx': 3412,\n",
       " 'tomorrow': 4505,\n",
       " 'air': 501,\n",
       " 'deicing': 1444,\n",
       " 'connect': 1264,\n",
       " 'helpful': 2256,\n",
       " 'hoping': 2308,\n",
       " 'catch': 1051,\n",
       " 'garywerk': 2087,\n",
       " 'poor': 3478,\n",
       " 'excuse': 1769,\n",
       " 'towards': 4526,\n",
       " 'front': 2037,\n",
       " 'sandwiches': 3908,\n",
       " 'pay': 3361,\n",
       " 'nice': 3116,\n",
       " 'partners': 3342,\n",
       " 'delays': 1450,\n",
       " 'keep': 2605,\n",
       " 'increasing': 2421,\n",
       " 'every': 1751,\n",
       " '20': 116,\n",
       " 'min': 2967,\n",
       " 'ftlauderdalesun': 2048,\n",
       " 'orlandosentinel': 3268,\n",
       " '1ateafnc6r': 110,\n",
       " 'upcoming': 4709,\n",
       " 'rr': 3869,\n",
       " 'changes': 1080,\n",
       " 'deval': 1490,\n",
       " 'tell': 4396,\n",
       " 'anymore': 615,\n",
       " 'loyal': 2810,\n",
       " 'far': 1837,\n",
       " 'rt': 3871,\n",
       " 'virginamerica': 4786,\n",
       " 'man': 2855,\n",
       " 'steel': 4239,\n",
       " 'might': 2957,\n",
       " 'faster': 1842,\n",
       " 'wifi': 4912,\n",
       " 'just': 2581,\n",
       " 'sciencebehindtheexperience': 3942,\n",
       " 'fgrbpazsix': 1876,\n",
       " 'travels': 4550,\n",
       " 'both': 916,\n",
       " 'use': 4738,\n",
       " 'membership': 2923,\n",
       " 'ua5282': 4617,\n",
       " 'x2': 4990,\n",
       " 'getting': 2108,\n",
       " 'overnight': 3303,\n",
       " 'unitedairlines': 4676,\n",
       " '1706': 87,\n",
       " 'charged': 1087,\n",
       " '600': 312,\n",
       " 'oh': 3219,\n",
       " 'well': 4874,\n",
       " 'inconvenience': 2416,\n",
       " 'tryagain': 4573,\n",
       " 'claim': 1142,\n",
       " 'number': 3175,\n",
       " 'haven': 2232,\n",
       " 'iad': 2357,\n",
       " 'since': 4065,\n",
       " 'fort': 2005,\n",
       " 'launder': 2675,\n",
       " 'dale': 1392,\n",
       " 'switch': 4342,\n",
       " 'ridiculous': 3831,\n",
       " 'didn': 1506,\n",
       " 'notify': 3163,\n",
       " 'through': 4459,\n",
       " 'epic': 1722,\n",
       " 'fail': 1815,\n",
       " 'find': 1901,\n",
       " 'las': 2669,\n",
       " 'dia': 1496,\n",
       " 'sat': 3913,\n",
       " 'hour': 2324,\n",
       " 'update': 4710,\n",
       " 'start': 4220,\n",
       " 'daily': 1389,\n",
       " 'b737': 754,\n",
       " '700': 330,\n",
       " 'columbus': 1192,\n",
       " 'oakland': 3191,\n",
       " '8aug': 379,\n",
       " 'avgeek': 730,\n",
       " '3472': 208,\n",
       " 'rather': 3652,\n",
       " 'while': 4899,\n",
       " 'exposed': 1796,\n",
       " 'nasty': 3071,\n",
       " 'contagious': 1283,\n",
       " 'virus': 4789,\n",
       " 'then': 4430,\n",
       " 'work': 4948,\n",
       " 'wth': 4985,\n",
       " 'changed': 1079,\n",
       " 'flightr': 1950,\n",
       " 'date': 1407,\n",
       " '4th': 280,\n",
       " 'rebooked': 3678,\n",
       " 'flighted': 1940,\n",
       " 'woo': 4945,\n",
       " 'hoo': 2296,\n",
       " 'laguardiaair': 2656,\n",
       " 'bumped': 968,\n",
       " 'hrl': 2336,\n",
       " 'minutes': 2977,\n",
       " 'early': 1647,\n",
       " 'staff': 4208,\n",
       " 'asked': 678,\n",
       " 'problem': 3550,\n",
       " 'after': 483,\n",
       " 'night': 3119,\n",
       " 'charlotte': 1092,\n",
       " 'seriously': 3997,\n",
       " 'debating': 1428,\n",
       " 'minute': 2976,\n",
       " 'tarmac': 4379,\n",
       " 'leaves': 2691,\n",
       " 'vanessaannz': 4762,\n",
       " 'accommodate': 436,\n",
       " 'inclemental': 2405,\n",
       " 'disruptions': 1556,\n",
       " 'lol': 2772,\n",
       " 'very': 4772,\n",
       " 'funny': 2065,\n",
       " 'kkwhb': 2631,\n",
       " 'paid': 3325,\n",
       " 'bird': 871,\n",
       " 'b46': 751,\n",
       " 'lady': 2654,\n",
       " 'system': 4355,\n",
       " 'dead': 1420,\n",
       " 'she': 4020,\n",
       " 'understand': 4652,\n",
       " 'albuquerque': 522,\n",
       " 'nm': 3124,\n",
       " 'usa': 4727,\n",
       " 'cebu': 1064,\n",
       " 'philippines': 3402,\n",
       " 'providing': 3580,\n",
       " 'educational': 1664,\n",
       " '800': 361,\n",
       " 'kids': 2622,\n",
       " 'row': 3865,\n",
       " '16': 71,\n",
       " '634': 316,\n",
       " 'specifics': 4179,\n",
       " 'run': 3879,\n",
       " 'depot': 1474,\n",
       " 'wd40': 4854,\n",
       " 'flighting': 1942,\n",
       " 'calls': 1011,\n",
       " 'mins': 2973,\n",
       " 'departure': 1469,\n",
       " '4125': 241,\n",
       " 'announced': 594,\n",
       " 'nor': 3142,\n",
       " 'status': 4233,\n",
       " 'everyone': 1752,\n",
       " 'standing': 4216,\n",
       " 'comeon': 1200,\n",
       " 'dmed': 1570,\n",
       " 'confirmation': 1256,\n",
       " 'gary': 2086,\n",
       " 'serving': 4003,\n",
       " 'fll': 1955,\n",
       " 'counter': 1325,\n",
       " 'really': 3668,\n",
       " 'blue': 889,\n",
       " 'makes': 2851,\n",
       " 'feel': 1861,\n",
       " 'delayedl': 1448,\n",
       " 'lovejetblue': 2802,\n",
       " 'pts': 3584,\n",
       " 'expired': 1791,\n",
       " 'few': 1871,\n",
       " 'ago': 493,\n",
       " 'were': 4878,\n",
       " 'planning': 3448,\n",
       " 'tight': 4474,\n",
       " 'budget': 956,\n",
       " 'kudos': 2646,\n",
       " 'robin': 3847,\n",
       " 'phxskyharbor': 3413,\n",
       " 'found': 2013,\n",
       " 'reuniting': 3820,\n",
       " 'ipad': 2483,\n",
       " 'delightful': 1454,\n",
       " 'killing': 2624,\n",
       " 'sandiego': 3906,\n",
       " 'sf': 4010,\n",
       " 'ugh': 4630,\n",
       " 'where': 4894,\n",
       " 'new': 3102,\n",
       " 'program': 3561,\n",
       " 'beneficial': 843,\n",
       " 'longstanding': 2777,\n",
       " 'consumers': 1278,\n",
       " 'pricing': 3537,\n",
       " 'years': 5011,\n",
       " '70': 329,\n",
       " 'bucks': 955,\n",
       " 'criminal': 1351,\n",
       " 'pricewise': 3535,\n",
       " 'jfk': 2554,\n",
       " 'incomprehensible': 2413,\n",
       " 'employee': 1688,\n",
       " 'knows': 2638,\n",
       " 'frm': 2035,\n",
       " '424': 246,\n",
       " 'lax': 2678,\n",
       " 'nyc': 3185,\n",
       " 'hr': 2335,\n",
       " 'booked': 906,\n",
       " 'having': 2234,\n",
       " 'issues': 2500,\n",
       " 'told': 4502,\n",
       " '20minute': 130,\n",
       " 'gone': 2142,\n",
       " 'take': 4365,\n",
       " 'offline': 3215,\n",
       " 'location': 2759,\n",
       " 'bags': 778,\n",
       " 'atlantic': 700,\n",
       " 'ploughs': 3464,\n",
       " 'lone': 2774,\n",
       " 'furrow': 2067,\n",
       " 'middleeast': 2954,\n",
       " 'vw4p4t4tlh': 4804,\n",
       " 'thenationaluae': 4431,\n",
       " 'worst': 4964,\n",
       " 'access': 434,\n",
       " 'moved': 3030,\n",
       " 'hard': 2218,\n",
       " 'schedule': 3937,\n",
       " 'delta': 1458,\n",
       " 'wonderful': 4942,\n",
       " 'job': 2567,\n",
       " 'daughter': 1409,\n",
       " 'myself': 3054,\n",
       " 'pgh': 3395,\n",
       " 'orlando': 3267,\n",
       " 'stop': 4261,\n",
       " 'madness': 2837,\n",
       " 'fleet': 1926,\n",
       " 'fleek': 1925,\n",
       " '7x9usbj2fv': 358,\n",
       " 'disappointed': 1528,\n",
       " 'level': 2709,\n",
       " 'communication': 1215,\n",
       " 'such': 4295,\n",
       " 'bummer': 966,\n",
       " 'rock': 3849,\n",
       " '680': 319,\n",
       " 'en': 1693,\n",
       " 'route': 3860,\n",
       " 'dca': 1416,\n",
       " 'bwi': 986,\n",
       " 'diverting': 1565,\n",
       " 'rdu': 3655,\n",
       " 'sucks': 4297,\n",
       " 'conflicting': 1260,\n",
       " 'stellar': 4241,\n",
       " 'earned': 1649,\n",
       " 'business': 978,\n",
       " 'attention': 709,\n",
       " 'detail': 1488,\n",
       " 'consider': 1270,\n",
       " '00pm': 3,\n",
       " 'fast': 1841,\n",
       " 'reconsider': 3689,\n",
       " 'means': 2904,\n",
       " 'possibility': 3491,\n",
       " 'change': 1078,\n",
       " 'fine': 1903,\n",
       " 'done': 1587,\n",
       " 'purchase': 3592,\n",
       " 'try': 4572,\n",
       " 'most': 3025,\n",
       " 'thought': 4452,\n",
       " 'sort': 4149,\n",
       " 'bearable': 815,\n",
       " 'houston': 2329,\n",
       " 'morning': 3022,\n",
       " 'operation': 3250,\n",
       " 'does': 1575,\n",
       " 'mean': 2901,\n",
       " 'god': 2135,\n",
       " 'woke': 4937,\n",
       " 'voucher': 4798,\n",
       " 'code': 1185,\n",
       " 'enter': 1711,\n",
       " 'checkout': 1105,\n",
       " 'page': 3323,\n",
       " 'pls': 3465,\n",
       " 'amazing': 557,\n",
       " 'view': 4781,\n",
       " 'approach': 639,\n",
       " 'a68d5fulmh': 400,\n",
       " 'landing': 2661,\n",
       " 'anchorage': 583,\n",
       " 'fairbanks': 1824,\n",
       " 'fjkvqmbmas': 1921,\n",
       " 'monitor': 3013,\n",
       " 'aa111': 402,\n",
       " 'refund': 3713,\n",
       " 'mdbeei': 2897,\n",
       " 'mcmullen': 2893,\n",
       " 'phf': 3399,\n",
       " 'terminal': 4400,\n",
       " 'iah': 2359,\n",
       " 'idea': 2367,\n",
       " 'mess': 2936,\n",
       " 'plans': 3449,\n",
       " 'treat': 4551,\n",
       " 'big': 864,\n",
       " 'deal': 1422,\n",
       " 'generic': 2098,\n",
       " 'form': 2002,\n",
       " 'tons': 4508,\n",
       " 'fields': 1885,\n",
       " 'premier': 3517,\n",
       " 'platinum': 3452,\n",
       " 'servicefail': 4001,\n",
       " 'shout': 4039,\n",
       " 'diane': 1500,\n",
       " 'eyw': 1805,\n",
       " 'little': 2736,\n",
       " 'disappointment': 1530,\n",
       " 'before': 828,\n",
       " 'kept': 2610,\n",
       " '12': 40,\n",
       " 'without': 4932,\n",
       " 'options': 3256,\n",
       " 'flightling': 1946,\n",
       " 'exams': 1762,\n",
       " 'easiest': 1652,\n",
       " 'loveeee': 2801,\n",
       " 'derekc21': 1476,\n",
       " 'leave': 2690,\n",
       " 'jaipur': 2528,\n",
       " 'dehli': 1443,\n",
       " 'delhi': 1452,\n",
       " 'abilities': 418,\n",
       " 'magic': 2839,\n",
       " 'ask': 677,\n",
       " 'j_beatz247': 2521,\n",
       " 'teach': 4387,\n",
       " 'marketing': 2873,\n",
       " 'university': 4682,\n",
       " 'gladly': 2127,\n",
       " 'consult': 1276,\n",
       " 'passengers': 3349,\n",
       " 'official': 3213,\n",
       " 'airlines': 507,\n",
       " 'divadapouch': 1563,\n",
       " 'aka': 517,\n",
       " 'thepoopqueen': 4434,\n",
       " 'xxy2d2imnp': 5000,\n",
       " 'sick': 4050,\n",
       " 'joke': 2570,\n",
       " 'toyingwithouremotions': 4527,\n",
       " 'blown': 888,\n",
       " 'away': 740,\n",
       " 'hospitality': 2315,\n",
       " 'crutches': 1356,\n",
       " 'tsa': 4577,\n",
       " 'board': 895,\n",
       " '1534': 61,\n",
       " 'understanding': 4655,\n",
       " 'able': 419,\n",
       " 'did': 1505,\n",
       " 'many': 2865,\n",
       " 'other': 3276,\n",
       " 'chose': 1130,\n",
       " 'reservation': 3787,\n",
       " 'sync': 4350,\n",
       " 'updates': 4712,\n",
       " '1917': 105,\n",
       " 'philly': 3403,\n",
       " 'la': 2650,\n",
       " 'close': 1166,\n",
       " 'twitter': 4596,\n",
       " 'letting': 2708,\n",
       " 'redeem': 3701,\n",
       " 'points': 3471,\n",
       " 'packages': 3320,\n",
       " 'magically': 2841,\n",
       " '01': 4,\n",
       " 'felt': 1866,\n",
       " 'baitandswitch': 780,\n",
       " 'misfortune': 2982,\n",
       " '44': 254,\n",
       " 'countries': 1327,\n",
       " 'flown': 1959,\n",
       " 'outrageous': 3289,\n",
       " 'frustrated': 2041,\n",
       " 'compensate': 1228,\n",
       " 'appropriately': 641,\n",
       " 'screw': 3944,\n",
       " 'royally': 3868,\n",
       " 'fakesincerity': 1826,\n",
       " 'stahp': 4209,\n",
       " 'bm2unraoni': 890,\n",
       " 'virginatlantic': 4787,\n",
       " 'gma': 2131,\n",
       " 'ourprincess': 3282,\n",
       " 'some': 4130,\n",
       " '778aztdaer': 351,\n",
       " 'unacceptable': 4638,\n",
       " 'holdtime': 2285,\n",
       " 'upp41abxrq': 4718,\n",
       " 'absolute': 424,\n",
       " '40': 237,\n",
       " 'layover': 2679,\n",
       " 'let': 2703,\n",
       " 'door': 1594,\n",
       " 'closed': 1167,\n",
       " '24': 149,\n",
       " 'released': 3738,\n",
       " 'others': 3277,\n",
       " 'deplaning': 1473,\n",
       " 'peopleon': 3378,\n",
       " 'bridge': 935,\n",
       " 'hfof33iyhi': 2265,\n",
       " '3729': 217,\n",
       " 'shuttle': 4048,\n",
       " 'enough': 1707,\n",
       " 'operators': 3252,\n",
       " 'handle': 2199,\n",
       " 'americanairlines': 567,\n",
       " 'internet': 2466,\n",
       " 'give': 2121,\n",
       " 'thing': 4441,\n",
       " 'consistent': 1273,\n",
       " 'unfortunately': 4665,\n",
       " 'doing': 1580,\n",
       " 'alwaysdelayedonunited': 551,\n",
       " 'available': 727,\n",
       " 'until': 4705,\n",
       " 'taken': 4367,\n",
       " 'tweet': 4590,\n",
       " 'commend': 1206,\n",
       " 'down': 1602,\n",
       " 'tried': 4556,\n",
       " 'twice': 4595,\n",
       " 'seem': 3973,\n",
       " 'fortunemagazine': 2007,\n",
       " 'congrats': 1263,\n",
       " 'spanish': 4172,\n",
       " 'suppose': 4320,\n",
       " 'fl': 1922,\n",
       " 'yeah': 5009,\n",
       " 'define': 1438,\n",
       " 'incidentals': 2403,\n",
       " 'spend': 4182,\n",
       " 'gear': 2094,\n",
       " 'waste': 4840,\n",
       " '1041': 22,\n",
       " 'savannah': 3919,\n",
       " 'ga': 2077,\n",
       " 'maintenance': 2847,\n",
       " 'issue': 2498,\n",
       " 'geneva': 2099,\n",
       " 'meal': 2900,\n",
       " 'cover': 1334,\n",
       " 'plate': 3451,\n",
       " 'spaghetti': 4169,\n",
       " 'wrong': 4980,\n",
       " '1415': 54,\n",
       " 'waited': 4810,\n",
       " 'pilot': 3424,\n",
       " 'boston': 913,\n",
       " 'reassign': 3675,\n",
       " 'him': 2273,\n",
       " 'endless': 1698,\n",
       " 'clue': 1174,\n",
       " 'place': 3439,\n",
       " 'stay': 4234,\n",
       " 'de': 1417,\n",
       " 'ice': 2360,\n",
       " 'taxing': 4382,\n",
       " 'makestoomuchsense': 2852,\n",
       " 'shouldhaveflowndelta': 4036,\n",
       " 'unitedsucks': 4680,\n",
       " 'reserve': 3789,\n",
       " 'transfer': 4538,\n",
       " 'ord': 3259,\n",
       " 'evv': 1756,\n",
       " 'georgia': 2101,\n",
       " 'american': 564,\n",
       " 'tired': 4485,\n",
       " 'grumpy': 2182,\n",
       " 'name': 3062,\n",
       " 'which': 4898,\n",
       " 'fixed': 1918,\n",
       " 'cabin': 998,\n",
       " 'vacancies': 4753,\n",
       " 'relationship': 3732,\n",
       " 'terribly': 4403,\n",
       " 'saddening': 3891,\n",
       " 'suck': 4296,\n",
       " 'meaning': 2902,\n",
       " 'contingency': 1287,\n",
       " 'plan': 3442,\n",
       " 'reply': 3761,\n",
       " 'forms': 2004,\n",
       " 'chicago': 1114,\n",
       " 'leaving': 2692,\n",
       " 'calling': 1010,\n",
       " 'misplaced': 2986,\n",
       " 'disaster': 1531,\n",
       " 'across': 449,\n",
       " 'originally': 3265,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00p',\n",
       " '00pm',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '05am',\n",
       " '05pm',\n",
       " '0600',\n",
       " '07p',\n",
       " '08',\n",
       " '0ewj7oklji',\n",
       " '0jutcdrljl',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000cost',\n",
       " '1020',\n",
       " '1028',\n",
       " '103',\n",
       " '1032',\n",
       " '1041',\n",
       " '1065',\n",
       " '1071',\n",
       " '1079871763',\n",
       " '10am',\n",
       " '10mins',\n",
       " '11',\n",
       " '110',\n",
       " '1101',\n",
       " '1114',\n",
       " '1117',\n",
       " '112',\n",
       " '1140',\n",
       " '117',\n",
       " '1170',\n",
       " '118',\n",
       " '1183',\n",
       " '11am',\n",
       " '12',\n",
       " '1242',\n",
       " '1254',\n",
       " '125k',\n",
       " '1278',\n",
       " '12am',\n",
       " '12h',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '138',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '1415',\n",
       " '1472',\n",
       " '14am',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '150000',\n",
       " '1534',\n",
       " '1535',\n",
       " '1553',\n",
       " '1558',\n",
       " '1562',\n",
       " '1579',\n",
       " '1591',\n",
       " '15min',\n",
       " '15minutes',\n",
       " '15p',\n",
       " '16',\n",
       " '1601',\n",
       " '1605',\n",
       " '1618',\n",
       " '162',\n",
       " '1620',\n",
       " '1627',\n",
       " '1641',\n",
       " '165',\n",
       " '1665',\n",
       " '1687',\n",
       " '16hr',\n",
       " '16mont',\n",
       " '17',\n",
       " '1701',\n",
       " '1702',\n",
       " '1706',\n",
       " '1761',\n",
       " '1777',\n",
       " '1797',\n",
       " '17mph',\n",
       " '18',\n",
       " '180',\n",
       " '1814',\n",
       " '1855',\n",
       " '1856',\n",
       " '1874get',\n",
       " '1875',\n",
       " '1881',\n",
       " '1891',\n",
       " '18feb',\n",
       " '18fmr06mn6',\n",
       " '18th',\n",
       " '19',\n",
       " '1917',\n",
       " '1945',\n",
       " '1966',\n",
       " '19pm',\n",
       " '1am',\n",
       " '1ateafnc6r',\n",
       " '1b',\n",
       " '1hr',\n",
       " '1k',\n",
       " '1person',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '200fee',\n",
       " '2015',\n",
       " '2016',\n",
       " '2020',\n",
       " '2022',\n",
       " '2031',\n",
       " '2046',\n",
       " '206',\n",
       " '2063',\n",
       " '2065',\n",
       " '20min',\n",
       " '20mins',\n",
       " '20minute',\n",
       " '20minutes',\n",
       " '21',\n",
       " '2100',\n",
       " '2102',\n",
       " '211',\n",
       " '214',\n",
       " '21mbps',\n",
       " '21st',\n",
       " '22',\n",
       " '2208',\n",
       " '2214',\n",
       " '23',\n",
       " '2302',\n",
       " '2324',\n",
       " '236',\n",
       " '2390',\n",
       " '23oct',\n",
       " '23sep',\n",
       " '24',\n",
       " '2424',\n",
       " '2470',\n",
       " '24h',\n",
       " '24hrs',\n",
       " '25',\n",
       " '25m',\n",
       " '25min',\n",
       " '25yrs',\n",
       " '26',\n",
       " '2601',\n",
       " '2692',\n",
       " '26f',\n",
       " '26th',\n",
       " '27',\n",
       " '2707',\n",
       " '28',\n",
       " '29',\n",
       " '2954',\n",
       " '2962',\n",
       " '2a',\n",
       " '2d',\n",
       " '2days',\n",
       " '2dayslate',\n",
       " '2h30m',\n",
       " '2hours',\n",
       " '2hrs',\n",
       " '2hrs35minonhold',\n",
       " '2k',\n",
       " '2mins',\n",
       " '2mm',\n",
       " '2morrow',\n",
       " '2nd',\n",
       " '2ndary',\n",
       " '2pm',\n",
       " '2x',\n",
       " '2xdaily',\n",
       " '2y',\n",
       " '30',\n",
       " '30000ft',\n",
       " '300er',\n",
       " '3056',\n",
       " '3075',\n",
       " '30am',\n",
       " '30k',\n",
       " '30min',\n",
       " '3113',\n",
       " '317',\n",
       " '31daysofoscar',\n",
       " '31f',\n",
       " '32',\n",
       " '320008a',\n",
       " '3260',\n",
       " '330',\n",
       " '3322',\n",
       " '338',\n",
       " '340',\n",
       " '345',\n",
       " '3466',\n",
       " '3472',\n",
       " '348',\n",
       " '3487',\n",
       " '3494',\n",
       " '35',\n",
       " '350',\n",
       " '35x',\n",
       " '36',\n",
       " '3618',\n",
       " '3729',\n",
       " '38',\n",
       " '3837',\n",
       " '3854',\n",
       " '386',\n",
       " '3860',\n",
       " '3899',\n",
       " '39',\n",
       " '3933',\n",
       " '3935',\n",
       " '395',\n",
       " '3a',\n",
       " '3d',\n",
       " '3days',\n",
       " '3fq3xelbon',\n",
       " '3hrs',\n",
       " '3rd',\n",
       " '3x',\n",
       " '3x9nruovts',\n",
       " '3yr',\n",
       " '40',\n",
       " '400er',\n",
       " '403',\n",
       " '4050',\n",
       " '4125',\n",
       " '413',\n",
       " '4158',\n",
       " '416',\n",
       " '42',\n",
       " '424',\n",
       " '4278',\n",
       " '428',\n",
       " '430',\n",
       " '433',\n",
       " '4348',\n",
       " '435',\n",
       " '437',\n",
       " '44',\n",
       " '441',\n",
       " '4435',\n",
       " '4439',\n",
       " '4471',\n",
       " '4478',\n",
       " '45',\n",
       " '4524',\n",
       " '4567',\n",
       " '45am',\n",
       " '462',\n",
       " '463',\n",
       " '46min',\n",
       " '46mins',\n",
       " '46n9kdcsxu',\n",
       " '47',\n",
       " '475',\n",
       " '48',\n",
       " '480',\n",
       " '495',\n",
       " '4994',\n",
       " '4am',\n",
       " '4hrs',\n",
       " '4llwi5oxvo',\n",
       " '4ojrsdwpkk',\n",
       " '4q',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '502',\n",
       " '5080',\n",
       " '5097',\n",
       " '50k',\n",
       " '50min',\n",
       " '50pm',\n",
       " '514',\n",
       " '53',\n",
       " '5347',\n",
       " '539',\n",
       " '5418',\n",
       " '55',\n",
       " '555',\n",
       " '556',\n",
       " '55am',\n",
       " '55mins',\n",
       " '55pm',\n",
       " '56essfoowt',\n",
       " '574',\n",
       " '59',\n",
       " '597',\n",
       " '599',\n",
       " '5cdx2roae6',\n",
       " '5hrs',\n",
       " '5lbs',\n",
       " '5xgnyhgafz',\n",
       " '5xvnnmltiw',\n",
       " '5z9styuqj3',\n",
       " '60',\n",
       " '600',\n",
       " '601',\n",
       " '620',\n",
       " '623',\n",
       " '634',\n",
       " '645',\n",
       " '656',\n",
       " '680',\n",
       " '686',\n",
       " '699',\n",
       " '6a',\n",
       " '6am',\n",
       " '6may',\n",
       " '6pm',\n",
       " '6redd3vc73',\n",
       " '6rlz0ebk2x',\n",
       " '6tz6imqzlg',\n",
       " '70',\n",
       " '700',\n",
       " '704',\n",
       " '70min',\n",
       " '711',\n",
       " '715',\n",
       " '719',\n",
       " '72',\n",
       " '723',\n",
       " '725',\n",
       " '728',\n",
       " '73',\n",
       " '730',\n",
       " '7300',\n",
       " '737',\n",
       " '738',\n",
       " '745',\n",
       " '75',\n",
       " '750',\n",
       " '768',\n",
       " '776',\n",
       " '777',\n",
       " '778aztdaer',\n",
       " '79',\n",
       " '7am',\n",
       " '7d',\n",
       " '7e5bxwg16t',\n",
       " '7hours',\n",
       " '7th',\n",
       " '7x9usbj2fv',\n",
       " '7xmav13g2w',\n",
       " '80',\n",
       " '800',\n",
       " '805',\n",
       " '80sweresomuchfun',\n",
       " '80th',\n",
       " '815',\n",
       " '820pm',\n",
       " '823',\n",
       " '830',\n",
       " '833',\n",
       " '838',\n",
       " '85',\n",
       " '850',\n",
       " '86',\n",
       " '871',\n",
       " '88',\n",
       " '883',\n",
       " '894',\n",
       " '8am',\n",
       " '8aug',\n",
       " '8c',\n",
       " '8fkqw',\n",
       " '8h4',\n",
       " '8pm',\n",
       " '8q6mfd',\n",
       " '8uxzj2',\n",
       " '8x7xvm',\n",
       " '8yr',\n",
       " '90',\n",
       " '919',\n",
       " '953',\n",
       " '9am',\n",
       " '9eueyxawcv',\n",
       " '9hour',\n",
       " '9xbo5dakak',\n",
       " 'a1',\n",
       " 'a20',\n",
       " 'a320',\n",
       " 'a380s',\n",
       " 'a49',\n",
       " 'a68d5fulmh',\n",
       " 'aa',\n",
       " 'aa111',\n",
       " 'aa1119',\n",
       " 'aa1401',\n",
       " 'aa1469',\n",
       " 'aa157',\n",
       " 'aa3390',\n",
       " 'aa45',\n",
       " 'aa5',\n",
       " 'aadv',\n",
       " 'aadvantage',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abc',\n",
       " 'abc11_wtvd',\n",
       " 'abc7newsbayarea',\n",
       " 'abi',\n",
       " 'abilities',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abq',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoulutely',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accidents',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'acct',\n",
       " 'accurate',\n",
       " 'accused',\n",
       " 'acebo6elpa',\n",
       " 'achieving',\n",
       " 'acosta',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'active',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acu',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addair',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'admiral',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adv',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advertise',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'aesthetics',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agencies',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agt',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahlxhhkiyn',\n",
       " 'ahold',\n",
       " 'ai0yzwt8za',\n",
       " 'air',\n",
       " 'aircanada',\n",
       " 'aircraft',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlinequality',\n",
       " 'airlines',\n",
       " 'airnzusa',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airpt',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'aisles',\n",
       " 'aka',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alan_bledsoe',\n",
       " 'alaska',\n",
       " 'albuquerque',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alfamilyoffour',\n",
       " 'ali',\n",
       " 'alist',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allergic',\n",
       " 'alliance',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'altonbrownlive',\n",
       " 'always',\n",
       " 'alwaysdelayed',\n",
       " 'alwaysdelayedonunited',\n",
       " 'alwayshappensthere',\n",
       " 'alwayslate',\n",
       " 'am',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amazing',\n",
       " 'amazingflightcrew',\n",
       " 'amazingly',\n",
       " 'amen',\n",
       " 'amenities',\n",
       " 'amenity',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanairbr',\n",
       " 'americanairlines',\n",
       " 'americanairlinesfail',\n",
       " 'americanview',\n",
       " 'amex',\n",
       " 'amiltx3',\n",
       " 'amm',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amsterdam',\n",
       " 'amypoehler',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'analysts',\n",
       " 'anaphylaxis',\n",
       " 'anarchy',\n",
       " 'anchorage',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andrewfallis',\n",
       " 'angel',\n",
       " 'angry',\n",
       " 'angrytraveler',\n",
       " 'animal',\n",
       " 'annamarie',\n",
       " 'anniversary',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announcements',\n",
       " 'announces',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'anotherdisappointment',\n",
       " 'ans',\n",
       " 'ansleyhutson',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antitrust',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apeared',\n",
       " 'apologies',\n",
       " 'apologize',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appease',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approval',\n",
       " 'approximate',\n",
       " 'april',\n",
       " 'aptzpurop4',\n",
       " 'aqjn4hwnac',\n",
       " 'ar0vaylmfc',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'argentina',\n",
       " 'argued',\n",
       " 'argument',\n",
       " 'armrest',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangements',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'article',\n",
       " 'aruba',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ase',\n",
       " 'ashamed',\n",
       " 'ashleykatherton',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askpaypal',\n",
       " 'asks',\n",
       " 'aspen',\n",
       " 'aspenbaggagefail',\n",
       " 'ass',\n",
       " 'assaulted',\n",
       " 'assed',\n",
       " 'asshole',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assume',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'astounded',\n",
       " 'at',\n",
       " 'athletes',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atrocious',\n",
       " 'attdt',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attendants',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'atx',\n",
       " 'auditorium',\n",
       " 'aufm4xdaj2',\n",
       " 'august',\n",
       " 'aus',\n",
       " 'austic',\n",
       " 'austin',\n",
       " 'austinairport',\n",
       " 'australia',\n",
       " 'authority',\n",
       " 'auto',\n",
       " 'automated',\n",
       " 'automatically',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avatars',\n",
       " 'averaging',\n",
       " 'avgeek',\n",
       " 'aviation',\n",
       " 'avis',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'aw',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awrd',\n",
       " 'awww',\n",
       " 'aye',\n",
       " 'az',\n",
       " 'b1',\n",
       " 'b12',\n",
       " 'b4',\n",
       " 'b40',\n",
       " 'b46',\n",
       " 'b5ttno68xu',\n",
       " 'b6',\n",
       " 'b737',\n",
       " 'b767',\n",
       " 'b787',\n",
       " 'b787fans',\n",
       " 'ba1506',\n",
       " 'ba_usa',\n",
       " 'baby',\n",
       " 'babyfood',\n",
       " 'bach',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'backs',\n",
       " 'bad',\n",
       " 'badcustomerservice',\n",
       " 'badcustomersrvice',\n",
       " 'badge',\n",
       " 'badges',\n",
       " 'badpolicy',\n",
       " 'badservice',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'baggagefail',\n",
       " 'baggagelost',\n",
       " 'bags',\n",
       " 'bagsflyfreebutnotwithme',\n",
       " 'baitandswitch',\n",
       " 'baked',\n",
       " 'balance',\n",
       " 'baldordash',\n",
       " 'ball',\n",
       " 'ballin',\n",
       " 'baltimore',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'banned',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barely',\n",
       " 'barking',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basketball',\n",
       " 'bathrooms',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bbb_media',\n",
       " 'bc',\n",
       " 'bcn',\n",
       " 'bday',\n",
       " 'bdl',\n",
       " 'bdng',\n",
       " 'be',\n",
       " 'be4',\n",
       " 'beach',\n",
       " 'bearable',\n",
       " 'beat',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautifull',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bebetter',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begrudgingly',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'belabor',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'bellagio',\n",
       " 'belongings',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'bergstrom',\n",
       " 'best',\n",
       " 'bestairline',\n",
       " 'bestairlineever',\n",
       " 'bestemployees',\n",
       " 'bestinclass',\n",
       " 'bet',\n",
       " 'betch',\n",
       " 'better',\n",
       " 'betty',\n",
       " 'between',\n",
       " 'beverages',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bhooiyt6zq',\n",
       " 'biceps',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'biggie',\n",
       " 'bill',\n",
       " 'billions',\n",
       " 'bin',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'biz',\n",
       " 'black',\n",
       " 'blackberry10',\n",
       " 'blackmailed',\n",
       " 'blaming',\n",
       " 'blanc',\n",
       " 'blankets',\n",
       " 'blew',\n",
       " 'blocked',\n",
       " 'bloombergnews',\n",
       " 'bloombergradio',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bm2unraoni',\n",
       " 'bmi',\n",
       " 'bna',\n",
       " 'bnflhpxtmw',\n",
       " 'bngpli8jt6',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boarding',\n",
       " 'boards',\n",
       " 'boeing',\n",
       " 'bohnjai',\n",
       " 'boise',\n",
       " 'bom',\n",
       " 'bonus',\n",
       " 'bonuses',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'boom',\n",
       " 'booted',\n",
       " 'booze',\n",
       " 'border',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bostongarden',\n",
       " 'bostonlogan',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bots',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'bqonpa',\n",
       " 'brand',\n",
       " 'brandloveaffair',\n",
       " 'brandmance',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'brian',\n",
       " 'bridesmaid',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brisk',\n",
       " 'british_airways',\n",
       " 'bro',\n",
       " 'brochure',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'browsers',\n",
       " 'brussels',\n",
       " 'brutal',\n",
       " 'bs',\n",
       " 'bsuxlu',\n",
       " 'btv',\n",
       " 'btw',\n",
       " 'bucks',\n",
       " 'budget',\n",
       " 'buf',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'bugging',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bummed',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumper',\n",
       " 'bums',\n",
       " 'bunch',\n",
       " 'bundle',\n",
       " 'bundleup',\n",
       " 'burbank',\n",
       " 'burn',\n",
       " 'burroughs',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'businessfirst',\n",
       " 'bussey',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'bwi',\n",
       " 'by',\n",
       " 'by3vdiosua',\n",
       " 'bzwgp7adve',\n",
       " 'c12',\n",
       " 'c16',\n",
       " 'c26',\n",
       " 'c4',\n",
       " 'c47',\n",
       " 'c7tpdkqulm',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cable',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x5045 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 40030 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(df.loc[indexes, 'text'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(df.loc[indexes, 'text'].str.lower()).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00p</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05am</th>\n",
       "      <th>05pm</th>\n",
       "      <th>0600</th>\n",
       "      <th>...</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zero</th>\n",
       "      <th>zfv</th>\n",
       "      <th>zgoqoxjbqy</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zrh_airport</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zv2pt6trk9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  00p  00pm  01  02  03  05am  05pm  0600  ...  yyz  zero  zfv  \\\n",
       "0   0    0    0     0   0   0   0     0     0     0  ...    0     0    0   \n",
       "1   0    0    0     0   0   0   0     0     0     0  ...    0     0    0   \n",
       "2   0    0    0     0   0   0   0     0     0     0  ...    0     0    0   \n",
       "3   0    0    0     0   0   0   0     0     0     0  ...    0     0    0   \n",
       "4   0    0    0     0   0   0   0     0     0     0  ...    0     0    0   \n",
       "\n",
       "   zgoqoxjbqy  zip  zone  zoom  zrh_airport  zurich  zv2pt6trk9  \n",
       "0           0    0     0     0            0       0           0  \n",
       "1           0    0     0     0            0       0           0  \n",
       "2           0    0     0     0            0       0           0  \n",
       "3           0    0     0     0            0       0           0  \n",
       "4           0    0     0     0            0       0           0  \n",
       "\n",
       "[5 rows x 5045 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(cv.transform(df.loc[indexes, 'text'].str.lower()).todense(), columns = sorted(cv.vocabulary_))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.sum()>10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to              1473\n",
       "the              970\n",
       "you              794\n",
       "united           704\n",
       "for              686\n",
       "flight           669\n",
       "on               656\n",
       "and              639\n",
       "my               539\n",
       "usairways        537\n",
       "is               501\n",
       "in               484\n",
       "americanair      479\n",
       "southwestair     436\n",
       "it               430\n",
       "jetblue          388\n",
       "of               355\n",
       "can              326\n",
       "me               310\n",
       "your             297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sum().sort_values(ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 68)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data.loc[:,data.sum() > 105]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_df = airline_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat((airline_df, data_df), axis = 1)\n",
    "Y = df.loc[indexes, 'airline_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>US Airways</th>\n",
       "      <th>United</th>\n",
       "      <th>Virgin America</th>\n",
       "      <th>all</th>\n",
       "      <th>americanair</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>usairways</th>\n",
       "      <th>virginamerica</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>what</th>\n",
       "      <th>why</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      American  Delta  Southwest  US Airways  United  Virgin America  all  \\\n",
       "0            0      1          0           0       0               0    0   \n",
       "1            0      1          0           0       0               0    0   \n",
       "2            0      0          1           0       0               0    1   \n",
       "3            1      0          0           0       0               0    0   \n",
       "4            0      1          0           0       0               0    0   \n",
       "...        ...    ...        ...         ...     ...             ...  ...   \n",
       "2495         0      0          0           0       1               0    0   \n",
       "2496         0      0          0           0       1               0    0   \n",
       "2497         0      0          1           0       0               0    0   \n",
       "2498         0      0          0           0       1               0    0   \n",
       "2499         0      0          1           0       0               0    0   \n",
       "\n",
       "      americanair  amp  an  ...  usairways  virginamerica  was  we  what  why  \\\n",
       "0               0    0   0  ...          0              0    0   0     0    0   \n",
       "1               0    0   0  ...          0              0    0   0     0    0   \n",
       "2               0    0   0  ...          0              0    0   0     0    0   \n",
       "3               1    0   0  ...          0              0    0   0     0    0   \n",
       "4               0    0   0  ...          0              0    0   0     0    0   \n",
       "...           ...  ...  ..  ...        ...            ...  ...  ..   ...  ...   \n",
       "2495            0    0   0  ...          0              0    1   0     0    0   \n",
       "2496            0    0   0  ...          0              0    0   0     0    0   \n",
       "2497            0    0   0  ...          0              0    0   0     0    0   \n",
       "2498            0    0   0  ...          0              0    0   0     0    0   \n",
       "2499            0    0   0  ...          0              0    0   0     0    0   \n",
       "\n",
       "      will  with  you  your  \n",
       "0        0     0    0     0  \n",
       "1        0     0    0     0  \n",
       "2        0     0    0     0  \n",
       "3        0     0    1     0  \n",
       "4        0     0    0     0  \n",
       "...    ...   ...  ...   ...  \n",
       "2495     0     0    1     0  \n",
       "2496     0     0    1     0  \n",
       "2497     0     0    1     1  \n",
       "2498     1     0    0     0  \n",
       "2499     0     0    1     0  \n",
       "\n",
       "[2500 rows x 74 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'positive', ..., 'negative', 'negative',\n",
       "       'neutral'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.656 0.654 0.65  0.666 0.644] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61  0.7   0.64  0.646 0.636] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.6464000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "model = AdaBoostClassifier(estimator=dt,random_state=1)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.722 0.758 0.726 0.764 0.754] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7447999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.714 0.734 0.738 0.724 0.712] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7243999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.706 0.748 0.736 0.738 0.746] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "model = HistGradientBoostingClassifier(random_state=1)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.702 0.742 0.738 0.712 0.712] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=1,max_iter=1000)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.714 0.734 0.73  0.722 0.712] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "sv = SVC(kernel='rbf',probability=True)\n",
    "model = AdaBoostClassifier(estimator=sv)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.706 0.726 0.736 0.708 0.71 ] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7172000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "model = AdaBoostClassifier(estimator=lr)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.712 0.744 0.71  0.718 0.752] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7272000000000001\n"
     ]
    }
   ],
   "source": [
    "# xgboost - if we tune will cross every other library\n",
    "import xgboost as xgb \n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "results = cross_val_score(model,X,y_encoded, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73  0.736 0.724 0.748 0.732] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.734\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(verbose=False)\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.453343\n",
      "[LightGBM] [Info] Start training from score -1.632195\n",
      "[LightGBM] [Info] Start training from score -1.777857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.453343\n",
      "[LightGBM] [Info] Start training from score -1.632195\n",
      "[LightGBM] [Info] Start training from score -1.777857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 236\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.453343\n",
      "[LightGBM] [Info] Start training from score -1.632195\n",
      "[LightGBM] [Info] Start training from score -1.777857\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 235\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.452557\n",
      "[LightGBM] [Info] Start training from score -1.632195\n",
      "[LightGBM] [Info] Start training from score -1.780820\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 235\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.453343\n",
      "[LightGBM] [Info] Start training from score -1.629641\n",
      "[LightGBM] [Info] Start training from score -1.780820\n",
      "[0.71  0.764 0.742 0.738 0.736] \n",
      "------------------------------- \n",
      "Avg 5 Folds 0.7380000000000001\n"
     ]
    }
   ],
   "source": [
    "# lightgbm - good for large datasets\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier()\n",
    "\n",
    "results = cross_val_score(model,X,Y, cv=skf,scoring='accuracy')\n",
    "print(results,\"\\n-------------------------------\",\"\\nAvg 5 Folds\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [00:08<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -0.461401\n",
      "[LightGBM] [Info] Start training from score -1.633731\n",
      "[LightGBM] [Info] Start training from score -1.746404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:08<00:00,  3.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>None</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>None</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.57</td>\n",
       "      <td>None</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>None</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.56</td>\n",
       "      <td>None</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "      <td>None</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.55</td>\n",
       "      <td>None</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>None</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.54</td>\n",
       "      <td>None</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.53</td>\n",
       "      <td>None</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.53</td>\n",
       "      <td>None</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.52</td>\n",
       "      <td>None</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>None</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.33</td>\n",
       "      <td>None</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
       "Model                                                                          \n",
       "NearestCentroid                    0.65               0.61    None      0.67   \n",
       "LGBMClassifier                     0.72               0.60    None      0.71   \n",
       "SGDClassifier                      0.69               0.60    None      0.69   \n",
       "ExtraTreesClassifier               0.72               0.58    None      0.70   \n",
       "LinearDiscriminantAnalysis         0.72               0.58    None      0.70   \n",
       "RandomForestClassifier             0.73               0.58    None      0.71   \n",
       "LogisticRegression                 0.70               0.57    None      0.69   \n",
       "BernoulliNB                        0.69               0.57    None      0.68   \n",
       "LinearSVC                          0.71               0.56    None      0.69   \n",
       "SVC                                0.72               0.56    None      0.70   \n",
       "RidgeClassifierCV                  0.73               0.56    None      0.70   \n",
       "AdaBoostClassifier                 0.69               0.56    None      0.68   \n",
       "BaggingClassifier                  0.69               0.56    None      0.67   \n",
       "KNeighborsClassifier               0.62               0.56    None      0.64   \n",
       "RidgeClassifier                    0.72               0.56    None      0.70   \n",
       "PassiveAggressiveClassifier        0.68               0.55    None      0.66   \n",
       "CalibratedClassifierCV             0.73               0.55    None      0.69   \n",
       "GaussianNB                         0.52               0.54    None      0.55   \n",
       "DecisionTreeClassifier             0.62               0.54    None      0.63   \n",
       "LabelPropagation                   0.66               0.53    None      0.65   \n",
       "LabelSpreading                     0.66               0.53    None      0.65   \n",
       "Perceptron                         0.67               0.52    None      0.65   \n",
       "ExtraTreeClassifier                0.60               0.50    None      0.61   \n",
       "QuadraticDiscriminantAnalysis      0.41               0.45    None      0.42   \n",
       "DummyClassifier                    0.64               0.33    None      0.50   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "NearestCentroid                      0.07  \n",
       "LGBMClassifier                       0.36  \n",
       "SGDClassifier                        0.14  \n",
       "ExtraTreesClassifier                 0.40  \n",
       "LinearDiscriminantAnalysis           0.09  \n",
       "RandomForestClassifier               0.82  \n",
       "LogisticRegression                   0.18  \n",
       "BernoulliNB                          0.04  \n",
       "LinearSVC                            0.94  \n",
       "SVC                                  0.43  \n",
       "RidgeClassifierCV                    0.10  \n",
       "AdaBoostClassifier                   0.37  \n",
       "BaggingClassifier                    0.15  \n",
       "KNeighborsClassifier                 0.20  \n",
       "RidgeClassifier                      0.07  \n",
       "PassiveAggressiveClassifier          0.09  \n",
       "CalibratedClassifierCV               2.91  \n",
       "GaussianNB                           0.04  \n",
       "DecisionTreeClassifier               0.04  \n",
       "LabelPropagation                     0.24  \n",
       "LabelSpreading                       0.32  \n",
       "Perceptron                           0.07  \n",
       "ExtraTreeClassifier                  0.05  \n",
       "QuadraticDiscriminantAnalysis        0.14  \n",
       "DummyClassifier                      0.02  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lazy predict\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=.5,random_state =123)\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H20.ai(paid)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>American</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>US Airways</th>\n",
       "      <th>United</th>\n",
       "      <th>Virgin America</th>\n",
       "      <th>all</th>\n",
       "      <th>americanair</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>us</th>\n",
       "      <th>usairways</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>what</th>\n",
       "      <th>why</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      American  Delta  Southwest  US Airways  United  Virgin America  all  \\\n",
       "0            1      0          0           0       0               0    0   \n",
       "1            0      0          0           0       1               0    0   \n",
       "2            0      0          0           1       0               0    0   \n",
       "3            0      0          1           0       0               0    0   \n",
       "4            0      0          0           0       1               0    0   \n",
       "...        ...    ...        ...         ...     ...             ...  ...   \n",
       "2495         0      0          0           0       1               0    0   \n",
       "2496         0      0          1           0       0               0    0   \n",
       "2497         0      0          0           1       0               0    0   \n",
       "2498         0      0          0           1       0               0    0   \n",
       "2499         1      0          0           0       0               0    0   \n",
       "\n",
       "      americanair  amp  an  ...  us  usairways  was  we  what  why  will  \\\n",
       "0               1    0   0  ...   0          0    0   0     0    0     0   \n",
       "1               0    0   0  ...   0          0    0   0     0    0     0   \n",
       "2               1    0   0  ...   0          1    0   0     0    0     0   \n",
       "3               0    0   0  ...   0          0    0   0     0    0     0   \n",
       "4               0    0   0  ...   0          0    0   0     0    0     0   \n",
       "...           ...  ...  ..  ...  ..        ...  ...  ..   ...  ...   ...   \n",
       "2495            0    1   0  ...   0          0    0   1     0    0     0   \n",
       "2496            0    0   0  ...   0          0    0   0     1    0     0   \n",
       "2497            0    0   0  ...   0          1    0   0     0    0     0   \n",
       "2498            0    0   0  ...   0          1    1   0     0    0     0   \n",
       "2499            1    0   0  ...   1          0    0   0     0    0     0   \n",
       "\n",
       "      with  you  your  \n",
       "0        0    0     0  \n",
       "1        0    0     0  \n",
       "2        0    0     0  \n",
       "3        0    1     0  \n",
       "4        1    2     1  \n",
       "...    ...  ...   ...  \n",
       "2495     0    0     0  \n",
       "2496     0    0     0  \n",
       "2497     0    1     0  \n",
       "2498     0    0     0  \n",
       "2499     0    1     0  \n",
       "\n",
       "[2500 rows x 67 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fbff6_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fbff6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fbff6_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_fbff6_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fbff6_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_fbff6_row0_col1\" class=\"data row0 col1\" >777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fbff6_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_fbff6_row1_col1\" class=\"data row1 col1\" >output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fbff6_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_fbff6_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fbff6_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_fbff6_row3_col1\" class=\"data row3 col1\" >negative: 0, neutral: 1, positive: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fbff6_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_fbff6_row4_col1\" class=\"data row4 col1\" >(2500, 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fbff6_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_fbff6_row5_col1\" class=\"data row5 col1\" >(2500, 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_fbff6_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_fbff6_row6_col1\" class=\"data row6 col1\" >(1750, 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_fbff6_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_fbff6_row7_col1\" class=\"data row7 col1\" >(750, 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_fbff6_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_fbff6_row8_col1\" class=\"data row8 col1\" >74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_fbff6_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_fbff6_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_fbff6_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_fbff6_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_fbff6_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_fbff6_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_fbff6_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_fbff6_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_fbff6_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_fbff6_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_fbff6_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_fbff6_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_fbff6_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_fbff6_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_fbff6_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_fbff6_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_fbff6_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_fbff6_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_fbff6_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_fbff6_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbff6_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_fbff6_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_fbff6_row19_col1\" class=\"data row19 col1\" >c88c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22e352deeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "X['output'] = Y \n",
    "X.head(5)\n",
    "\n",
    "# pycaret needs a dataframe , with the target column(s)\n",
    "s = setup(X,target='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56bec th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56bec_row0_col0, #T_56bec_row0_col2, #T_56bec_row0_col6, #T_56bec_row1_col0, #T_56bec_row1_col1, #T_56bec_row1_col3, #T_56bec_row1_col4, #T_56bec_row1_col5, #T_56bec_row1_col7, #T_56bec_row2_col0, #T_56bec_row2_col1, #T_56bec_row2_col2, #T_56bec_row2_col3, #T_56bec_row2_col4, #T_56bec_row2_col5, #T_56bec_row2_col6, #T_56bec_row2_col7, #T_56bec_row3_col0, #T_56bec_row3_col1, #T_56bec_row3_col2, #T_56bec_row3_col3, #T_56bec_row3_col4, #T_56bec_row3_col5, #T_56bec_row3_col6, #T_56bec_row3_col7, #T_56bec_row4_col0, #T_56bec_row4_col1, #T_56bec_row4_col2, #T_56bec_row4_col3, #T_56bec_row4_col4, #T_56bec_row4_col5, #T_56bec_row4_col6, #T_56bec_row4_col7, #T_56bec_row5_col0, #T_56bec_row5_col1, #T_56bec_row5_col2, #T_56bec_row5_col3, #T_56bec_row5_col4, #T_56bec_row5_col5, #T_56bec_row5_col6, #T_56bec_row5_col7, #T_56bec_row6_col0, #T_56bec_row6_col1, #T_56bec_row6_col2, #T_56bec_row6_col3, #T_56bec_row6_col4, #T_56bec_row6_col5, #T_56bec_row6_col6, #T_56bec_row6_col7, #T_56bec_row7_col0, #T_56bec_row7_col1, #T_56bec_row7_col2, #T_56bec_row7_col3, #T_56bec_row7_col4, #T_56bec_row7_col5, #T_56bec_row7_col6, #T_56bec_row7_col7, #T_56bec_row8_col0, #T_56bec_row8_col1, #T_56bec_row8_col2, #T_56bec_row8_col3, #T_56bec_row8_col4, #T_56bec_row8_col5, #T_56bec_row8_col6, #T_56bec_row8_col7, #T_56bec_row9_col0, #T_56bec_row9_col1, #T_56bec_row9_col2, #T_56bec_row9_col3, #T_56bec_row9_col4, #T_56bec_row9_col5, #T_56bec_row9_col6, #T_56bec_row9_col7, #T_56bec_row10_col0, #T_56bec_row10_col1, #T_56bec_row10_col2, #T_56bec_row10_col3, #T_56bec_row10_col4, #T_56bec_row10_col5, #T_56bec_row10_col6, #T_56bec_row10_col7, #T_56bec_row11_col0, #T_56bec_row11_col1, #T_56bec_row11_col2, #T_56bec_row11_col3, #T_56bec_row11_col4, #T_56bec_row11_col5, #T_56bec_row11_col6, #T_56bec_row11_col7, #T_56bec_row12_col0, #T_56bec_row12_col1, #T_56bec_row12_col2, #T_56bec_row12_col3, #T_56bec_row12_col4, #T_56bec_row12_col5, #T_56bec_row12_col6, #T_56bec_row12_col7, #T_56bec_row13_col0, #T_56bec_row13_col1, #T_56bec_row13_col2, #T_56bec_row13_col3, #T_56bec_row13_col4, #T_56bec_row13_col5, #T_56bec_row13_col6, #T_56bec_row13_col7, #T_56bec_row14_col0, #T_56bec_row14_col1, #T_56bec_row14_col2, #T_56bec_row14_col3, #T_56bec_row14_col4, #T_56bec_row14_col5, #T_56bec_row14_col6, #T_56bec_row14_col7, #T_56bec_row15_col0, #T_56bec_row15_col1, #T_56bec_row15_col2, #T_56bec_row15_col3, #T_56bec_row15_col4, #T_56bec_row15_col5, #T_56bec_row15_col6, #T_56bec_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56bec_row0_col1, #T_56bec_row0_col3, #T_56bec_row0_col4, #T_56bec_row0_col5, #T_56bec_row0_col7, #T_56bec_row1_col2, #T_56bec_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_56bec_row0_col8, #T_56bec_row1_col8, #T_56bec_row2_col8, #T_56bec_row3_col8, #T_56bec_row4_col8, #T_56bec_row6_col8, #T_56bec_row7_col8, #T_56bec_row8_col8, #T_56bec_row9_col8, #T_56bec_row10_col8, #T_56bec_row11_col8, #T_56bec_row13_col8, #T_56bec_row14_col8, #T_56bec_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_56bec_row5_col8, #T_56bec_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56bec\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56bec_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_56bec_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_56bec_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_56bec_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_56bec_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_56bec_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_56bec_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_56bec_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_56bec_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "      <td id=\"T_56bec_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_56bec_row0_col1\" class=\"data row0 col1\" >0.7331</td>\n",
       "      <td id=\"T_56bec_row0_col2\" class=\"data row0 col2\" >0.8372</td>\n",
       "      <td id=\"T_56bec_row0_col3\" class=\"data row0 col3\" >0.7331</td>\n",
       "      <td id=\"T_56bec_row0_col4\" class=\"data row0 col4\" >0.7120</td>\n",
       "      <td id=\"T_56bec_row0_col5\" class=\"data row0 col5\" >0.7132</td>\n",
       "      <td id=\"T_56bec_row0_col6\" class=\"data row0 col6\" >0.4498</td>\n",
       "      <td id=\"T_56bec_row0_col7\" class=\"data row0 col7\" >0.4613</td>\n",
       "      <td id=\"T_56bec_row0_col8\" class=\"data row0 col8\" >1.8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_56bec_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_56bec_row1_col1\" class=\"data row1 col1\" >0.7269</td>\n",
       "      <td id=\"T_56bec_row1_col2\" class=\"data row1 col2\" >0.8388</td>\n",
       "      <td id=\"T_56bec_row1_col3\" class=\"data row1 col3\" >0.7269</td>\n",
       "      <td id=\"T_56bec_row1_col4\" class=\"data row1 col4\" >0.7085</td>\n",
       "      <td id=\"T_56bec_row1_col5\" class=\"data row1 col5\" >0.7125</td>\n",
       "      <td id=\"T_56bec_row1_col6\" class=\"data row1 col6\" >0.4525</td>\n",
       "      <td id=\"T_56bec_row1_col7\" class=\"data row1 col7\" >0.4586</td>\n",
       "      <td id=\"T_56bec_row1_col8\" class=\"data row1 col8\" >0.3410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row2\" class=\"row_heading level0 row2\" >lr</th>\n",
       "      <td id=\"T_56bec_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_56bec_row2_col1\" class=\"data row2 col1\" >0.7263</td>\n",
       "      <td id=\"T_56bec_row2_col2\" class=\"data row2 col2\" >0.8270</td>\n",
       "      <td id=\"T_56bec_row2_col3\" class=\"data row2 col3\" >0.7263</td>\n",
       "      <td id=\"T_56bec_row2_col4\" class=\"data row2 col4\" >0.7065</td>\n",
       "      <td id=\"T_56bec_row2_col5\" class=\"data row2 col5\" >0.7047</td>\n",
       "      <td id=\"T_56bec_row2_col6\" class=\"data row2 col6\" >0.4309</td>\n",
       "      <td id=\"T_56bec_row2_col7\" class=\"data row2 col7\" >0.4445</td>\n",
       "      <td id=\"T_56bec_row2_col8\" class=\"data row2 col8\" >1.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_56bec_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_56bec_row3_col1\" class=\"data row3 col1\" >0.7229</td>\n",
       "      <td id=\"T_56bec_row3_col2\" class=\"data row3 col2\" >0.8130</td>\n",
       "      <td id=\"T_56bec_row3_col3\" class=\"data row3 col3\" >0.7229</td>\n",
       "      <td id=\"T_56bec_row3_col4\" class=\"data row3 col4\" >0.6994</td>\n",
       "      <td id=\"T_56bec_row3_col5\" class=\"data row3 col5\" >0.6994</td>\n",
       "      <td id=\"T_56bec_row3_col6\" class=\"data row3 col6\" >0.4216</td>\n",
       "      <td id=\"T_56bec_row3_col7\" class=\"data row3 col7\" >0.4364</td>\n",
       "      <td id=\"T_56bec_row3_col8\" class=\"data row3 col8\" >0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n",
       "      <td id=\"T_56bec_row4_col0\" class=\"data row4 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_56bec_row4_col1\" class=\"data row4 col1\" >0.7229</td>\n",
       "      <td id=\"T_56bec_row4_col2\" class=\"data row4 col2\" >0.8096</td>\n",
       "      <td id=\"T_56bec_row4_col3\" class=\"data row4 col3\" >0.7229</td>\n",
       "      <td id=\"T_56bec_row4_col4\" class=\"data row4 col4\" >0.6995</td>\n",
       "      <td id=\"T_56bec_row4_col5\" class=\"data row4 col5\" >0.6994</td>\n",
       "      <td id=\"T_56bec_row4_col6\" class=\"data row4 col6\" >0.4216</td>\n",
       "      <td id=\"T_56bec_row4_col7\" class=\"data row4 col7\" >0.4363</td>\n",
       "      <td id=\"T_56bec_row4_col8\" class=\"data row4 col8\" >0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "      <td id=\"T_56bec_row5_col0\" class=\"data row5 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_56bec_row5_col1\" class=\"data row5 col1\" >0.7211</td>\n",
       "      <td id=\"T_56bec_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_56bec_row5_col3\" class=\"data row5 col3\" >0.7211</td>\n",
       "      <td id=\"T_56bec_row5_col4\" class=\"data row5 col4\" >0.6992</td>\n",
       "      <td id=\"T_56bec_row5_col5\" class=\"data row5 col5\" >0.6881</td>\n",
       "      <td id=\"T_56bec_row5_col6\" class=\"data row5 col6\" >0.3945</td>\n",
       "      <td id=\"T_56bec_row5_col7\" class=\"data row5 col7\" >0.4222</td>\n",
       "      <td id=\"T_56bec_row5_col8\" class=\"data row5 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row6\" class=\"row_heading level0 row6\" >xgboost</th>\n",
       "      <td id=\"T_56bec_row6_col0\" class=\"data row6 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_56bec_row6_col1\" class=\"data row6 col1\" >0.7166</td>\n",
       "      <td id=\"T_56bec_row6_col2\" class=\"data row6 col2\" >0.8348</td>\n",
       "      <td id=\"T_56bec_row6_col3\" class=\"data row6 col3\" >0.7166</td>\n",
       "      <td id=\"T_56bec_row6_col4\" class=\"data row6 col4\" >0.6985</td>\n",
       "      <td id=\"T_56bec_row6_col5\" class=\"data row6 col5\" >0.7021</td>\n",
       "      <td id=\"T_56bec_row6_col6\" class=\"data row6 col6\" >0.4305</td>\n",
       "      <td id=\"T_56bec_row6_col7\" class=\"data row6 col7\" >0.4366</td>\n",
       "      <td id=\"T_56bec_row6_col8\" class=\"data row6 col8\" >0.1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n",
       "      <td id=\"T_56bec_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_56bec_row7_col1\" class=\"data row7 col1\" >0.7143</td>\n",
       "      <td id=\"T_56bec_row7_col2\" class=\"data row7 col2\" >0.8261</td>\n",
       "      <td id=\"T_56bec_row7_col3\" class=\"data row7 col3\" >0.7143</td>\n",
       "      <td id=\"T_56bec_row7_col4\" class=\"data row7 col4\" >0.6939</td>\n",
       "      <td id=\"T_56bec_row7_col5\" class=\"data row7 col5\" >0.6805</td>\n",
       "      <td id=\"T_56bec_row7_col6\" class=\"data row7 col6\" >0.3762</td>\n",
       "      <td id=\"T_56bec_row7_col7\" class=\"data row7 col7\" >0.4033</td>\n",
       "      <td id=\"T_56bec_row7_col8\" class=\"data row7 col8\" >0.3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_56bec_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_56bec_row8_col1\" class=\"data row8 col1\" >0.7137</td>\n",
       "      <td id=\"T_56bec_row8_col2\" class=\"data row8 col2\" >0.8169</td>\n",
       "      <td id=\"T_56bec_row8_col3\" class=\"data row8 col3\" >0.7137</td>\n",
       "      <td id=\"T_56bec_row8_col4\" class=\"data row8 col4\" >0.6928</td>\n",
       "      <td id=\"T_56bec_row8_col5\" class=\"data row8 col5\" >0.6919</td>\n",
       "      <td id=\"T_56bec_row8_col6\" class=\"data row8 col6\" >0.4066</td>\n",
       "      <td id=\"T_56bec_row8_col7\" class=\"data row8 col7\" >0.4191</td>\n",
       "      <td id=\"T_56bec_row8_col8\" class=\"data row8 col8\" >0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row9\" class=\"row_heading level0 row9\" >ada</th>\n",
       "      <td id=\"T_56bec_row9_col0\" class=\"data row9 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_56bec_row9_col1\" class=\"data row9 col1\" >0.7120</td>\n",
       "      <td id=\"T_56bec_row9_col2\" class=\"data row9 col2\" >0.7773</td>\n",
       "      <td id=\"T_56bec_row9_col3\" class=\"data row9 col3\" >0.7120</td>\n",
       "      <td id=\"T_56bec_row9_col4\" class=\"data row9 col4\" >0.6929</td>\n",
       "      <td id=\"T_56bec_row9_col5\" class=\"data row9 col5\" >0.6934</td>\n",
       "      <td id=\"T_56bec_row9_col6\" class=\"data row9 col6\" >0.4122</td>\n",
       "      <td id=\"T_56bec_row9_col7\" class=\"data row9 col7\" >0.4217</td>\n",
       "      <td id=\"T_56bec_row9_col8\" class=\"data row9 col8\" >0.0780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_56bec_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_56bec_row10_col1\" class=\"data row10 col1\" >0.7057</td>\n",
       "      <td id=\"T_56bec_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_56bec_row10_col3\" class=\"data row10 col3\" >0.7057</td>\n",
       "      <td id=\"T_56bec_row10_col4\" class=\"data row10 col4\" >0.6905</td>\n",
       "      <td id=\"T_56bec_row10_col5\" class=\"data row10 col5\" >0.6847</td>\n",
       "      <td id=\"T_56bec_row10_col6\" class=\"data row10 col6\" >0.3962</td>\n",
       "      <td id=\"T_56bec_row10_col7\" class=\"data row10 col7\" >0.4112</td>\n",
       "      <td id=\"T_56bec_row10_col8\" class=\"data row10 col8\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_56bec_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_56bec_row11_col1\" class=\"data row11 col1\" >0.6309</td>\n",
       "      <td id=\"T_56bec_row11_col2\" class=\"data row11 col2\" >0.7687</td>\n",
       "      <td id=\"T_56bec_row11_col3\" class=\"data row11 col3\" >0.6309</td>\n",
       "      <td id=\"T_56bec_row11_col4\" class=\"data row11 col4\" >0.6674</td>\n",
       "      <td id=\"T_56bec_row11_col5\" class=\"data row11 col5\" >0.6303</td>\n",
       "      <td id=\"T_56bec_row11_col6\" class=\"data row11 col6\" >0.3356</td>\n",
       "      <td id=\"T_56bec_row11_col7\" class=\"data row11 col7\" >0.3483</td>\n",
       "      <td id=\"T_56bec_row11_col8\" class=\"data row11 col8\" >0.0270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_56bec_row12_col0\" class=\"data row12 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_56bec_row12_col1\" class=\"data row12 col1\" >0.6309</td>\n",
       "      <td id=\"T_56bec_row12_col2\" class=\"data row12 col2\" >0.5000</td>\n",
       "      <td id=\"T_56bec_row12_col3\" class=\"data row12 col3\" >0.6309</td>\n",
       "      <td id=\"T_56bec_row12_col4\" class=\"data row12 col4\" >0.3980</td>\n",
       "      <td id=\"T_56bec_row12_col5\" class=\"data row12 col5\" >0.4881</td>\n",
       "      <td id=\"T_56bec_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_56bec_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_56bec_row12_col8\" class=\"data row12 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_56bec_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_56bec_row13_col1\" class=\"data row13 col1\" >0.6291</td>\n",
       "      <td id=\"T_56bec_row13_col2\" class=\"data row13 col2\" >0.6759</td>\n",
       "      <td id=\"T_56bec_row13_col3\" class=\"data row13 col3\" >0.6291</td>\n",
       "      <td id=\"T_56bec_row13_col4\" class=\"data row13 col4\" >0.6351</td>\n",
       "      <td id=\"T_56bec_row13_col5\" class=\"data row13 col5\" >0.6304</td>\n",
       "      <td id=\"T_56bec_row13_col6\" class=\"data row13 col6\" >0.3104</td>\n",
       "      <td id=\"T_56bec_row13_col7\" class=\"data row13 col7\" >0.3116</td>\n",
       "      <td id=\"T_56bec_row13_col8\" class=\"data row13 col8\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row14\" class=\"row_heading level0 row14\" >knn</th>\n",
       "      <td id=\"T_56bec_row14_col0\" class=\"data row14 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_56bec_row14_col1\" class=\"data row14 col1\" >0.6120</td>\n",
       "      <td id=\"T_56bec_row14_col2\" class=\"data row14 col2\" >0.7160</td>\n",
       "      <td id=\"T_56bec_row14_col3\" class=\"data row14 col3\" >0.6120</td>\n",
       "      <td id=\"T_56bec_row14_col4\" class=\"data row14 col4\" >0.6274</td>\n",
       "      <td id=\"T_56bec_row14_col5\" class=\"data row14 col5\" >0.6122</td>\n",
       "      <td id=\"T_56bec_row14_col6\" class=\"data row14 col6\" >0.2787</td>\n",
       "      <td id=\"T_56bec_row14_col7\" class=\"data row14 col7\" >0.2827</td>\n",
       "      <td id=\"T_56bec_row14_col8\" class=\"data row14 col8\" >0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56bec_level0_row15\" class=\"row_heading level0 row15\" >nb</th>\n",
       "      <td id=\"T_56bec_row15_col0\" class=\"data row15 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_56bec_row15_col1\" class=\"data row15 col1\" >0.5297</td>\n",
       "      <td id=\"T_56bec_row15_col2\" class=\"data row15 col2\" >0.7980</td>\n",
       "      <td id=\"T_56bec_row15_col3\" class=\"data row15 col3\" >0.5297</td>\n",
       "      <td id=\"T_56bec_row15_col4\" class=\"data row15 col4\" >0.6981</td>\n",
       "      <td id=\"T_56bec_row15_col5\" class=\"data row15 col5\" >0.5509</td>\n",
       "      <td id=\"T_56bec_row15_col6\" class=\"data row15 col6\" >0.2806</td>\n",
       "      <td id=\"T_56bec_row15_col7\" class=\"data row15 col7\" >0.3281</td>\n",
       "      <td id=\"T_56bec_row15_col8\" class=\"data row15 col8\" >0.0220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22e35269d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x22e356c7cd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm</th>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "      <td>sklearn.svm._classes.SVC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpc</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "      <td>xgboost.sklearn.XGBClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>catboost.core.CatBoostClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>sklearn.dummy.DummyClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "ID                                          \n",
       "lr                    Logistic Regression   \n",
       "knn                K Neighbors Classifier   \n",
       "nb                            Naive Bayes   \n",
       "dt               Decision Tree Classifier   \n",
       "svm                   SVM - Linear Kernel   \n",
       "rbfsvm                SVM - Radial Kernel   \n",
       "gpc           Gaussian Process Classifier   \n",
       "mlp                        MLP Classifier   \n",
       "ridge                    Ridge Classifier   \n",
       "rf               Random Forest Classifier   \n",
       "qda       Quadratic Discriminant Analysis   \n",
       "ada                  Ada Boost Classifier   \n",
       "gbc          Gradient Boosting Classifier   \n",
       "lda          Linear Discriminant Analysis   \n",
       "et                 Extra Trees Classifier   \n",
       "xgboost         Extreme Gradient Boosting   \n",
       "lightgbm  Light Gradient Boosting Machine   \n",
       "catboost              CatBoost Classifier   \n",
       "dummy                    Dummy Classifier   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
       "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
       "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
       "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
       "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
       "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
       "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
       "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
       "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
       "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
       "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
       "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
       "xgboost                       xgboost.sklearn.XGBClassifier   True  \n",
       "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
       "catboost                   catboost.core.CatBoostClassifier   True  \n",
       "dummy                         sklearn.dummy.DummyClassifier   True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'n_estimators':range(75, 125, 7),\n",
    "                'max_samples':np.linspace(0.5, 1, 6),\n",
    "                #'ccp_alpha':np.linspace(0, 0.0005, 5),\n",
    "                'max_features':np.linspace(0.05, 0.3,6),\n",
    "                'criterion':['gini','entropy']\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dc97e_row10_col0, #T_dc97e_row10_col1, #T_dc97e_row10_col2, #T_dc97e_row10_col3, #T_dc97e_row10_col4, #T_dc97e_row10_col5, #T_dc97e_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dc97e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dc97e_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_dc97e_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_dc97e_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_dc97e_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_dc97e_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_dc97e_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_dc97e_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dc97e_row0_col0\" class=\"data row0 col0\" >0.7429</td>\n",
       "      <td id=\"T_dc97e_row0_col1\" class=\"data row0 col1\" >0.8189</td>\n",
       "      <td id=\"T_dc97e_row0_col2\" class=\"data row0 col2\" >0.7429</td>\n",
       "      <td id=\"T_dc97e_row0_col3\" class=\"data row0 col3\" >0.7202</td>\n",
       "      <td id=\"T_dc97e_row0_col4\" class=\"data row0 col4\" >0.7192</td>\n",
       "      <td id=\"T_dc97e_row0_col5\" class=\"data row0 col5\" >0.4573</td>\n",
       "      <td id=\"T_dc97e_row0_col6\" class=\"data row0 col6\" >0.4745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dc97e_row1_col0\" class=\"data row1 col0\" >0.7200</td>\n",
       "      <td id=\"T_dc97e_row1_col1\" class=\"data row1 col1\" >0.8121</td>\n",
       "      <td id=\"T_dc97e_row1_col2\" class=\"data row1 col2\" >0.7200</td>\n",
       "      <td id=\"T_dc97e_row1_col3\" class=\"data row1 col3\" >0.6885</td>\n",
       "      <td id=\"T_dc97e_row1_col4\" class=\"data row1 col4\" >0.6917</td>\n",
       "      <td id=\"T_dc97e_row1_col5\" class=\"data row1 col5\" >0.4053</td>\n",
       "      <td id=\"T_dc97e_row1_col6\" class=\"data row1 col6\" >0.4221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dc97e_row2_col0\" class=\"data row2 col0\" >0.7314</td>\n",
       "      <td id=\"T_dc97e_row2_col1\" class=\"data row2 col1\" >0.7892</td>\n",
       "      <td id=\"T_dc97e_row2_col2\" class=\"data row2 col2\" >0.7314</td>\n",
       "      <td id=\"T_dc97e_row2_col3\" class=\"data row2 col3\" >0.7157</td>\n",
       "      <td id=\"T_dc97e_row2_col4\" class=\"data row2 col4\" >0.7094</td>\n",
       "      <td id=\"T_dc97e_row2_col5\" class=\"data row2 col5\" >0.4299</td>\n",
       "      <td id=\"T_dc97e_row2_col6\" class=\"data row2 col6\" >0.4478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dc97e_row3_col0\" class=\"data row3 col0\" >0.7086</td>\n",
       "      <td id=\"T_dc97e_row3_col1\" class=\"data row3 col1\" >0.7908</td>\n",
       "      <td id=\"T_dc97e_row3_col2\" class=\"data row3 col2\" >0.7086</td>\n",
       "      <td id=\"T_dc97e_row3_col3\" class=\"data row3 col3\" >0.6732</td>\n",
       "      <td id=\"T_dc97e_row3_col4\" class=\"data row3 col4\" >0.6673</td>\n",
       "      <td id=\"T_dc97e_row3_col5\" class=\"data row3 col5\" >0.3527</td>\n",
       "      <td id=\"T_dc97e_row3_col6\" class=\"data row3 col6\" >0.3836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_dc97e_row4_col0\" class=\"data row4 col0\" >0.7257</td>\n",
       "      <td id=\"T_dc97e_row4_col1\" class=\"data row4 col1\" >0.8582</td>\n",
       "      <td id=\"T_dc97e_row4_col2\" class=\"data row4 col2\" >0.7257</td>\n",
       "      <td id=\"T_dc97e_row4_col3\" class=\"data row4 col3\" >0.7076</td>\n",
       "      <td id=\"T_dc97e_row4_col4\" class=\"data row4 col4\" >0.7087</td>\n",
       "      <td id=\"T_dc97e_row4_col5\" class=\"data row4 col5\" >0.4395</td>\n",
       "      <td id=\"T_dc97e_row4_col6\" class=\"data row4 col6\" >0.4495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_dc97e_row5_col0\" class=\"data row5 col0\" >0.6971</td>\n",
       "      <td id=\"T_dc97e_row5_col1\" class=\"data row5 col1\" >0.7606</td>\n",
       "      <td id=\"T_dc97e_row5_col2\" class=\"data row5 col2\" >0.6971</td>\n",
       "      <td id=\"T_dc97e_row5_col3\" class=\"data row5 col3\" >0.6676</td>\n",
       "      <td id=\"T_dc97e_row5_col4\" class=\"data row5 col4\" >0.6723</td>\n",
       "      <td id=\"T_dc97e_row5_col5\" class=\"data row5 col5\" >0.3723</td>\n",
       "      <td id=\"T_dc97e_row5_col6\" class=\"data row5 col6\" >0.3846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_dc97e_row6_col0\" class=\"data row6 col0\" >0.7086</td>\n",
       "      <td id=\"T_dc97e_row6_col1\" class=\"data row6 col1\" >0.8171</td>\n",
       "      <td id=\"T_dc97e_row6_col2\" class=\"data row6 col2\" >0.7086</td>\n",
       "      <td id=\"T_dc97e_row6_col3\" class=\"data row6 col3\" >0.6893</td>\n",
       "      <td id=\"T_dc97e_row6_col4\" class=\"data row6 col4\" >0.6928</td>\n",
       "      <td id=\"T_dc97e_row6_col5\" class=\"data row6 col5\" >0.4102</td>\n",
       "      <td id=\"T_dc97e_row6_col6\" class=\"data row6 col6\" >0.4174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_dc97e_row7_col0\" class=\"data row7 col0\" >0.7429</td>\n",
       "      <td id=\"T_dc97e_row7_col1\" class=\"data row7 col1\" >0.8530</td>\n",
       "      <td id=\"T_dc97e_row7_col2\" class=\"data row7 col2\" >0.7429</td>\n",
       "      <td id=\"T_dc97e_row7_col3\" class=\"data row7 col3\" >0.7221</td>\n",
       "      <td id=\"T_dc97e_row7_col4\" class=\"data row7 col4\" >0.7245</td>\n",
       "      <td id=\"T_dc97e_row7_col5\" class=\"data row7 col5\" >0.4750</td>\n",
       "      <td id=\"T_dc97e_row7_col6\" class=\"data row7 col6\" >0.4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_dc97e_row8_col0\" class=\"data row8 col0\" >0.7371</td>\n",
       "      <td id=\"T_dc97e_row8_col1\" class=\"data row8 col1\" >0.8417</td>\n",
       "      <td id=\"T_dc97e_row8_col2\" class=\"data row8 col2\" >0.7371</td>\n",
       "      <td id=\"T_dc97e_row8_col3\" class=\"data row8 col3\" >0.7284</td>\n",
       "      <td id=\"T_dc97e_row8_col4\" class=\"data row8 col4\" >0.7237</td>\n",
       "      <td id=\"T_dc97e_row8_col5\" class=\"data row8 col5\" >0.4751</td>\n",
       "      <td id=\"T_dc97e_row8_col6\" class=\"data row8 col6\" >0.4819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_dc97e_row9_col0\" class=\"data row9 col0\" >0.7143</td>\n",
       "      <td id=\"T_dc97e_row9_col1\" class=\"data row9 col1\" >0.7882</td>\n",
       "      <td id=\"T_dc97e_row9_col2\" class=\"data row9 col2\" >0.7143</td>\n",
       "      <td id=\"T_dc97e_row9_col3\" class=\"data row9 col3\" >0.6815</td>\n",
       "      <td id=\"T_dc97e_row9_col4\" class=\"data row9 col4\" >0.6844</td>\n",
       "      <td id=\"T_dc97e_row9_col5\" class=\"data row9 col5\" >0.3989</td>\n",
       "      <td id=\"T_dc97e_row9_col6\" class=\"data row9 col6\" >0.4170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_dc97e_row10_col0\" class=\"data row10 col0\" >0.7229</td>\n",
       "      <td id=\"T_dc97e_row10_col1\" class=\"data row10 col1\" >0.8130</td>\n",
       "      <td id=\"T_dc97e_row10_col2\" class=\"data row10 col2\" >0.7229</td>\n",
       "      <td id=\"T_dc97e_row10_col3\" class=\"data row10 col3\" >0.6994</td>\n",
       "      <td id=\"T_dc97e_row10_col4\" class=\"data row10 col4\" >0.6994</td>\n",
       "      <td id=\"T_dc97e_row10_col5\" class=\"data row10 col5\" >0.4216</td>\n",
       "      <td id=\"T_dc97e_row10_col6\" class=\"data row10 col6\" >0.4364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc97e_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_dc97e_row11_col0\" class=\"data row11 col0\" >0.0150</td>\n",
       "      <td id=\"T_dc97e_row11_col1\" class=\"data row11 col1\" >0.0299</td>\n",
       "      <td id=\"T_dc97e_row11_col2\" class=\"data row11 col2\" >0.0150</td>\n",
       "      <td id=\"T_dc97e_row11_col3\" class=\"data row11 col3\" >0.0209</td>\n",
       "      <td id=\"T_dc97e_row11_col4\" class=\"data row11 col4\" >0.0197</td>\n",
       "      <td id=\"T_dc97e_row11_col5\" class=\"data row11 col5\" >0.0393</td>\n",
       "      <td id=\"T_dc97e_row11_col6\" class=\"data row11 col6\" >0.0356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22e3577ddc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b9969_row10_col0, #T_b9969_row10_col1, #T_b9969_row10_col2, #T_b9969_row10_col3, #T_b9969_row10_col4, #T_b9969_row10_col5, #T_b9969_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b9969\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b9969_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_b9969_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_b9969_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b9969_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_b9969_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_b9969_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_b9969_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b9969_row0_col0\" class=\"data row0 col0\" >0.7371</td>\n",
       "      <td id=\"T_b9969_row0_col1\" class=\"data row0 col1\" >0.8280</td>\n",
       "      <td id=\"T_b9969_row0_col2\" class=\"data row0 col2\" >0.7371</td>\n",
       "      <td id=\"T_b9969_row0_col3\" class=\"data row0 col3\" >0.7195</td>\n",
       "      <td id=\"T_b9969_row0_col4\" class=\"data row0 col4\" >0.7027</td>\n",
       "      <td id=\"T_b9969_row0_col5\" class=\"data row0 col5\" >0.4189</td>\n",
       "      <td id=\"T_b9969_row0_col6\" class=\"data row0 col6\" >0.4526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b9969_row1_col0\" class=\"data row1 col0\" >0.7600</td>\n",
       "      <td id=\"T_b9969_row1_col1\" class=\"data row1 col1\" >0.8163</td>\n",
       "      <td id=\"T_b9969_row1_col2\" class=\"data row1 col2\" >0.7600</td>\n",
       "      <td id=\"T_b9969_row1_col3\" class=\"data row1 col3\" >0.7433</td>\n",
       "      <td id=\"T_b9969_row1_col4\" class=\"data row1 col4\" >0.7310</td>\n",
       "      <td id=\"T_b9969_row1_col5\" class=\"data row1 col5\" >0.4785</td>\n",
       "      <td id=\"T_b9969_row1_col6\" class=\"data row1 col6\" >0.5079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b9969_row2_col0\" class=\"data row2 col0\" >0.7314</td>\n",
       "      <td id=\"T_b9969_row2_col1\" class=\"data row2 col1\" >0.8184</td>\n",
       "      <td id=\"T_b9969_row2_col2\" class=\"data row2 col2\" >0.7314</td>\n",
       "      <td id=\"T_b9969_row2_col3\" class=\"data row2 col3\" >0.7134</td>\n",
       "      <td id=\"T_b9969_row2_col4\" class=\"data row2 col4\" >0.7040</td>\n",
       "      <td id=\"T_b9969_row2_col5\" class=\"data row2 col5\" >0.4195</td>\n",
       "      <td id=\"T_b9969_row2_col6\" class=\"data row2 col6\" >0.4430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b9969_row3_col0\" class=\"data row3 col0\" >0.7086</td>\n",
       "      <td id=\"T_b9969_row3_col1\" class=\"data row3 col1\" >0.7987</td>\n",
       "      <td id=\"T_b9969_row3_col2\" class=\"data row3 col2\" >0.7086</td>\n",
       "      <td id=\"T_b9969_row3_col3\" class=\"data row3 col3\" >0.6823</td>\n",
       "      <td id=\"T_b9969_row3_col4\" class=\"data row3 col4\" >0.6650</td>\n",
       "      <td id=\"T_b9969_row3_col5\" class=\"data row3 col5\" >0.3419</td>\n",
       "      <td id=\"T_b9969_row3_col6\" class=\"data row3 col6\" >0.3806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b9969_row4_col0\" class=\"data row4 col0\" >0.6971</td>\n",
       "      <td id=\"T_b9969_row4_col1\" class=\"data row4 col1\" >0.8598</td>\n",
       "      <td id=\"T_b9969_row4_col2\" class=\"data row4 col2\" >0.6971</td>\n",
       "      <td id=\"T_b9969_row4_col3\" class=\"data row4 col3\" >0.6723</td>\n",
       "      <td id=\"T_b9969_row4_col4\" class=\"data row4 col4\" >0.6635</td>\n",
       "      <td id=\"T_b9969_row4_col5\" class=\"data row4 col5\" >0.3465</td>\n",
       "      <td id=\"T_b9969_row4_col6\" class=\"data row4 col6\" >0.3692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b9969_row5_col0\" class=\"data row5 col0\" >0.7029</td>\n",
       "      <td id=\"T_b9969_row5_col1\" class=\"data row5 col1\" >0.7881</td>\n",
       "      <td id=\"T_b9969_row5_col2\" class=\"data row5 col2\" >0.7029</td>\n",
       "      <td id=\"T_b9969_row5_col3\" class=\"data row5 col3\" >0.6719</td>\n",
       "      <td id=\"T_b9969_row5_col4\" class=\"data row5 col4\" >0.6695</td>\n",
       "      <td id=\"T_b9969_row5_col5\" class=\"data row5 col5\" >0.3645</td>\n",
       "      <td id=\"T_b9969_row5_col6\" class=\"data row5 col6\" >0.3866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b9969_row6_col0\" class=\"data row6 col0\" >0.7200</td>\n",
       "      <td id=\"T_b9969_row6_col1\" class=\"data row6 col1\" >0.8152</td>\n",
       "      <td id=\"T_b9969_row6_col2\" class=\"data row6 col2\" >0.7200</td>\n",
       "      <td id=\"T_b9969_row6_col3\" class=\"data row6 col3\" >0.7030</td>\n",
       "      <td id=\"T_b9969_row6_col4\" class=\"data row6 col4\" >0.6988</td>\n",
       "      <td id=\"T_b9969_row6_col5\" class=\"data row6 col5\" >0.4154</td>\n",
       "      <td id=\"T_b9969_row6_col6\" class=\"data row6 col6\" >0.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b9969_row7_col0\" class=\"data row7 col0\" >0.7543</td>\n",
       "      <td id=\"T_b9969_row7_col1\" class=\"data row7 col1\" >0.8502</td>\n",
       "      <td id=\"T_b9969_row7_col2\" class=\"data row7 col2\" >0.7543</td>\n",
       "      <td id=\"T_b9969_row7_col3\" class=\"data row7 col3\" >0.7459</td>\n",
       "      <td id=\"T_b9969_row7_col4\" class=\"data row7 col4\" >0.7327</td>\n",
       "      <td id=\"T_b9969_row7_col5\" class=\"data row7 col5\" >0.4818</td>\n",
       "      <td id=\"T_b9969_row7_col6\" class=\"data row7 col6\" >0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b9969_row8_col0\" class=\"data row8 col0\" >0.7257</td>\n",
       "      <td id=\"T_b9969_row8_col1\" class=\"data row8 col1\" >0.8270</td>\n",
       "      <td id=\"T_b9969_row8_col2\" class=\"data row8 col2\" >0.7257</td>\n",
       "      <td id=\"T_b9969_row8_col3\" class=\"data row8 col3\" >0.7154</td>\n",
       "      <td id=\"T_b9969_row8_col4\" class=\"data row8 col4\" >0.7067</td>\n",
       "      <td id=\"T_b9969_row8_col5\" class=\"data row8 col5\" >0.4382</td>\n",
       "      <td id=\"T_b9969_row8_col6\" class=\"data row8 col6\" >0.4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b9969_row9_col0\" class=\"data row9 col0\" >0.7371</td>\n",
       "      <td id=\"T_b9969_row9_col1\" class=\"data row9 col1\" >0.8050</td>\n",
       "      <td id=\"T_b9969_row9_col2\" class=\"data row9 col2\" >0.7371</td>\n",
       "      <td id=\"T_b9969_row9_col3\" class=\"data row9 col3\" >0.7203</td>\n",
       "      <td id=\"T_b9969_row9_col4\" class=\"data row9 col4\" >0.7022</td>\n",
       "      <td id=\"T_b9969_row9_col5\" class=\"data row9 col5\" >0.4254</td>\n",
       "      <td id=\"T_b9969_row9_col6\" class=\"data row9 col6\" >0.4618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_b9969_row10_col0\" class=\"data row10 col0\" >0.7274</td>\n",
       "      <td id=\"T_b9969_row10_col1\" class=\"data row10 col1\" >0.8207</td>\n",
       "      <td id=\"T_b9969_row10_col2\" class=\"data row10 col2\" >0.7274</td>\n",
       "      <td id=\"T_b9969_row10_col3\" class=\"data row10 col3\" >0.7087</td>\n",
       "      <td id=\"T_b9969_row10_col4\" class=\"data row10 col4\" >0.6976</td>\n",
       "      <td id=\"T_b9969_row10_col5\" class=\"data row10 col5\" >0.4131</td>\n",
       "      <td id=\"T_b9969_row10_col6\" class=\"data row10 col6\" >0.4385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9969_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_b9969_row11_col0\" class=\"data row11 col0\" >0.0198</td>\n",
       "      <td id=\"T_b9969_row11_col1\" class=\"data row11 col1\" >0.0208</td>\n",
       "      <td id=\"T_b9969_row11_col2\" class=\"data row11 col2\" >0.0198</td>\n",
       "      <td id=\"T_b9969_row11_col3\" class=\"data row11 col3\" >0.0251</td>\n",
       "      <td id=\"T_b9969_row11_col4\" class=\"data row11 col4\" >0.0235</td>\n",
       "      <td id=\"T_b9969_row11_col5\" class=\"data row11 col5\" >0.0466</td>\n",
       "      <td id=\"T_b9969_row11_col6\" class=\"data row11 col6\" >0.0456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22e356a8fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "myrf = create_model('rf')\n",
    "tuned_model = tune_model(myrf, custom_grid = hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=None, max_features=0.05,\n",
       "                       max_leaf_nodes=None, max_samples=0.9,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=82, n_jobs=-1, oob_score=False,\n",
       "                       random_state=777, verbose=0, warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=None, max_features=0.05,\n",
       "                       max_leaf_nodes=None, max_samples=0.9,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=82, n_jobs=-1, oob_score=False,\n",
       "                       random_state=777, verbose=0, warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features=0.05,\n",
       "                       max_leaf_nodes=None, max_samples=0.9,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=82, n_jobs=-1, oob_score=False,\n",
       "                       random_state=777, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 2, 1, 0, 1, 2, 0, 2, 2, 0, 0, 0,\n",
       "       2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.predict(X[:100].drop('output',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20731707, 0.65853659, 0.13414634],\n",
       "       [0.12195122, 0.27746322, 0.60058556],\n",
       "       [0.09756098, 0.07317073, 0.82926829],\n",
       "       [0.85365854, 0.03658537, 0.1097561 ],\n",
       "       [0.87804878, 0.07317073, 0.04878049],\n",
       "       [0.85365854, 0.07317073, 0.07317073],\n",
       "       [0.8902439 , 0.06097561, 0.04878049],\n",
       "       [0.98170732, 0.01829268, 0.        ],\n",
       "       [0.87804878, 0.02439024, 0.09756098],\n",
       "       [0.90243902, 0.06097561, 0.03658537],\n",
       "       [0.07317073, 0.91463415, 0.01219512],\n",
       "       [0.20731707, 0.69512195, 0.09756098],\n",
       "       [0.91463415, 0.04878049, 0.03658537],\n",
       "       [0.88414634, 0.04268293, 0.07317073],\n",
       "       [0.87804878, 0.03658537, 0.08536585],\n",
       "       [0.27256098, 0.39817073, 0.32926829],\n",
       "       [0.14634146, 0.79268293, 0.06097561],\n",
       "       [0.82926829, 0.12195122, 0.04878049],\n",
       "       [0.20731707, 0.09756098, 0.69512195],\n",
       "       [0.93902439, 0.02439024, 0.03658537],\n",
       "       [0.57317073, 0.37804878, 0.04878049],\n",
       "       [0.90243902, 0.06097561, 0.03658537],\n",
       "       [0.91463415, 0.04878049, 0.03658537],\n",
       "       [0.86585366, 0.09146341, 0.04268293],\n",
       "       [0.26829268, 0.09756098, 0.63414634],\n",
       "       [0.84146341, 0.07317073, 0.08536585],\n",
       "       [0.91463415, 0.04878049, 0.03658537],\n",
       "       [0.84146341, 0.09756098, 0.06097561],\n",
       "       [0.63414634, 0.34146341, 0.02439024],\n",
       "       [0.91463415, 0.07317073, 0.01219512],\n",
       "       [0.        , 0.45737339, 0.54262661],\n",
       "       [0.8902439 , 0.04878049, 0.06097561],\n",
       "       [0.59627371, 0.30633469, 0.0973916 ],\n",
       "       [0.07317073, 0.74181185, 0.18501742],\n",
       "       [0.82520325, 0.1504065 , 0.02439024],\n",
       "       [0.87804878, 0.08536585, 0.03658537],\n",
       "       [0.32926829, 0.62195122, 0.04878049],\n",
       "       [0.01219512, 0.83131665, 0.15648823],\n",
       "       [0.87804878, 0.1097561 , 0.01219512],\n",
       "       [0.86585366, 0.07317073, 0.06097561],\n",
       "       [0.48780488, 0.06097561, 0.45121951],\n",
       "       [0.07317073, 0.75087108, 0.17595819],\n",
       "       [0.81707317, 0.08536585, 0.09756098],\n",
       "       [0.91463415, 0.07804878, 0.00731707],\n",
       "       [0.03658537, 0.74483159, 0.21858304],\n",
       "       [0.92682927, 0.06097561, 0.01219512],\n",
       "       [0.90243902, 0.03658537, 0.06097561],\n",
       "       [0.35162602, 0.61178862, 0.03658537],\n",
       "       [0.85365854, 0.03658537, 0.1097561 ],\n",
       "       [0.6097561 , 0.26829268, 0.12195122],\n",
       "       [0.25609756, 0.65853659, 0.08536585],\n",
       "       [0.91463415, 0.06097561, 0.02439024],\n",
       "       [0.51219512, 0.15853659, 0.32926829],\n",
       "       [0.2804878 , 0.12195122, 0.59756098],\n",
       "       [0.2703252 , 0.07317073, 0.65650407],\n",
       "       [0.32357724, 0.06747967, 0.60894309],\n",
       "       [0.07317073, 0.91463415, 0.01219512],\n",
       "       [0.8902439 , 0.07317073, 0.03658537],\n",
       "       [0.19512195, 0.7804878 , 0.02439024],\n",
       "       [0.26829268, 0.14634146, 0.58536585],\n",
       "       [0.92682927, 0.04878049, 0.02439024],\n",
       "       [0.2804878 , 0.04878049, 0.67073171],\n",
       "       [0.1097561 , 0.01219512, 0.87804878],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.78861789, 0.17479675, 0.03658537],\n",
       "       [0.73170732, 0.2195122 , 0.04878049],\n",
       "       [0.18292683, 0.26829268, 0.54878049],\n",
       "       [0.08943089, 0.90243902, 0.00813008],\n",
       "       [0.93902439, 0.06097561, 0.        ],\n",
       "       [0.95644599, 0.04006969, 0.00348432],\n",
       "       [0.04573171, 0.76081591, 0.19345238],\n",
       "       [0.80487805, 0.07317073, 0.12195122],\n",
       "       [0.76829268, 0.20731707, 0.02439024],\n",
       "       [0.82926829, 0.14634146, 0.02439024],\n",
       "       [0.8902439 , 0.1097561 , 0.        ],\n",
       "       [0.8902439 , 0.08536585, 0.02439024],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.08536585, 0.70656698, 0.20806717],\n",
       "       [0.7804878 , 0.12195122, 0.09756098],\n",
       "       [0.95121951, 0.02439024, 0.02439024],\n",
       "       [0.85365854, 0.07317073, 0.07317073],\n",
       "       [0.85365854, 0.04878049, 0.09756098],\n",
       "       [0.8902439 , 0.0945122 , 0.0152439 ],\n",
       "       [0.79268293, 0.06097561, 0.14634146],\n",
       "       [0.34146341, 0.64634146, 0.01219512],\n",
       "       [0.90243902, 0.09756098, 0.        ],\n",
       "       [0.7804878 , 0.15853659, 0.06097561],\n",
       "       [0.91463415, 0.08536585, 0.        ],\n",
       "       [0.26829268, 0.70731707, 0.02439024],\n",
       "       [0.25853659, 0.10487805, 0.63658537],\n",
       "       [0.07317073, 0.03658537, 0.8902439 ],\n",
       "       [0.1097561 , 0.80487805, 0.08536585],\n",
       "       [0.2804878 , 0.01219512, 0.70731707],\n",
       "       [0.84146341, 0.06097561, 0.09756098],\n",
       "       [0.91463415, 0.07317073, 0.01219512],\n",
       "       [0.85365854, 0.1097561 , 0.03658537],\n",
       "       [0.95121951, 0.        , 0.04878049],\n",
       "       [0.18292683, 0.62195122, 0.19512195],\n",
       "       [0.96341463, 0.01219512, 0.02439024],\n",
       "       [0.96341463, 0.01219512, 0.02439024]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.predict_proba(X[:100].drop('output',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['American', 'Delta', 'Southwest', 'US Airways', 'United',\n",
       "       'Virgin America', 'all', 'americanair', 'amp', 'an', 'and', 'are', 'at',\n",
       "       'be', 'been', 'but', 'can', 'cancelled', 'co', 'customer', 'delayed',\n",
       "       'do', 'flight', 'flights', 'for', 'from', 'get', 'have', 'help', 'hold',\n",
       "       'hours', 'how', 'http', 'if', 'in', 'is', 'it', 'jetblue', 'just', 'me',\n",
       "       'my', 'no', 'not', 'now', 'of', 'on', 'our', 'out', 'service', 'so',\n",
       "       'southwestair', 'still', 'thank', 'thanks', 'that', 'the', 'there',\n",
       "       'they', 'this', 'time', 'to', 'united', 'up', 'us', 'usairways',\n",
       "       'virginamerica', 'was', 'we', 'what', 'why', 'will', 'with', 'you',\n",
       "       'your', 'output'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6d425_row10_col0, #T_6d425_row10_col1, #T_6d425_row10_col2, #T_6d425_row10_col3, #T_6d425_row10_col4, #T_6d425_row10_col5, #T_6d425_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6d425\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6d425_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_6d425_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_6d425_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_6d425_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_6d425_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_6d425_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_6d425_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6d425_row0_col0\" class=\"data row0 col0\" >0.6857</td>\n",
       "      <td id=\"T_6d425_row0_col1\" class=\"data row0 col1\" >0.7175</td>\n",
       "      <td id=\"T_6d425_row0_col2\" class=\"data row0 col2\" >0.6857</td>\n",
       "      <td id=\"T_6d425_row0_col3\" class=\"data row0 col3\" >0.7521</td>\n",
       "      <td id=\"T_6d425_row0_col4\" class=\"data row0 col4\" >0.5975</td>\n",
       "      <td id=\"T_6d425_row0_col5\" class=\"data row0 col5\" >0.2261</td>\n",
       "      <td id=\"T_6d425_row0_col6\" class=\"data row0 col6\" >0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6d425_row1_col0\" class=\"data row1 col0\" >0.6914</td>\n",
       "      <td id=\"T_6d425_row1_col1\" class=\"data row1 col1\" >0.6854</td>\n",
       "      <td id=\"T_6d425_row1_col2\" class=\"data row1 col2\" >0.6914</td>\n",
       "      <td id=\"T_6d425_row1_col3\" class=\"data row1 col3\" >0.5548</td>\n",
       "      <td id=\"T_6d425_row1_col4\" class=\"data row1 col4\" >0.5994</td>\n",
       "      <td id=\"T_6d425_row1_col5\" class=\"data row1 col5\" >0.2457</td>\n",
       "      <td id=\"T_6d425_row1_col6\" class=\"data row1 col6\" >0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6d425_row2_col0\" class=\"data row2 col0\" >0.6571</td>\n",
       "      <td id=\"T_6d425_row2_col1\" class=\"data row2 col1\" >0.7061</td>\n",
       "      <td id=\"T_6d425_row2_col2\" class=\"data row2 col2\" >0.6571</td>\n",
       "      <td id=\"T_6d425_row2_col3\" class=\"data row2 col3\" >0.5095</td>\n",
       "      <td id=\"T_6d425_row2_col4\" class=\"data row2 col4\" >0.5604</td>\n",
       "      <td id=\"T_6d425_row2_col5\" class=\"data row2 col5\" >0.1563</td>\n",
       "      <td id=\"T_6d425_row2_col6\" class=\"data row2 col6\" >0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6d425_row3_col0\" class=\"data row3 col0\" >0.6629</td>\n",
       "      <td id=\"T_6d425_row3_col1\" class=\"data row3 col1\" >0.6603</td>\n",
       "      <td id=\"T_6d425_row3_col2\" class=\"data row3 col2\" >0.6629</td>\n",
       "      <td id=\"T_6d425_row3_col3\" class=\"data row3 col3\" >0.5175</td>\n",
       "      <td id=\"T_6d425_row3_col4\" class=\"data row3 col4\" >0.5607</td>\n",
       "      <td id=\"T_6d425_row3_col5\" class=\"data row3 col5\" >0.1534</td>\n",
       "      <td id=\"T_6d425_row3_col6\" class=\"data row3 col6\" >0.2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6d425_row4_col0\" class=\"data row4 col0\" >0.6971</td>\n",
       "      <td id=\"T_6d425_row4_col1\" class=\"data row4 col1\" >0.7874</td>\n",
       "      <td id=\"T_6d425_row4_col2\" class=\"data row4 col2\" >0.6971</td>\n",
       "      <td id=\"T_6d425_row4_col3\" class=\"data row4 col3\" >0.5560</td>\n",
       "      <td id=\"T_6d425_row4_col4\" class=\"data row4 col4\" >0.6037</td>\n",
       "      <td id=\"T_6d425_row4_col5\" class=\"data row4 col5\" >0.2736</td>\n",
       "      <td id=\"T_6d425_row4_col6\" class=\"data row4 col6\" >0.3726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6d425_row5_col0\" class=\"data row5 col0\" >0.6514</td>\n",
       "      <td id=\"T_6d425_row5_col1\" class=\"data row5 col1\" >0.6628</td>\n",
       "      <td id=\"T_6d425_row5_col2\" class=\"data row5 col2\" >0.6514</td>\n",
       "      <td id=\"T_6d425_row5_col3\" class=\"data row5 col3\" >0.5060</td>\n",
       "      <td id=\"T_6d425_row5_col4\" class=\"data row5 col4\" >0.5615</td>\n",
       "      <td id=\"T_6d425_row5_col5\" class=\"data row5 col5\" >0.1792</td>\n",
       "      <td id=\"T_6d425_row5_col6\" class=\"data row5 col6\" >0.2307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6d425_row6_col0\" class=\"data row6 col0\" >0.6914</td>\n",
       "      <td id=\"T_6d425_row6_col1\" class=\"data row6 col1\" >0.6962</td>\n",
       "      <td id=\"T_6d425_row6_col2\" class=\"data row6 col2\" >0.6914</td>\n",
       "      <td id=\"T_6d425_row6_col3\" class=\"data row6 col3\" >0.5562</td>\n",
       "      <td id=\"T_6d425_row6_col4\" class=\"data row6 col4\" >0.5968</td>\n",
       "      <td id=\"T_6d425_row6_col5\" class=\"data row6 col5\" >0.2503</td>\n",
       "      <td id=\"T_6d425_row6_col6\" class=\"data row6 col6\" >0.3559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6d425_row7_col0\" class=\"data row7 col0\" >0.6571</td>\n",
       "      <td id=\"T_6d425_row7_col1\" class=\"data row7 col1\" >0.7095</td>\n",
       "      <td id=\"T_6d425_row7_col2\" class=\"data row7 col2\" >0.6571</td>\n",
       "      <td id=\"T_6d425_row7_col3\" class=\"data row7 col3\" >0.5171</td>\n",
       "      <td id=\"T_6d425_row7_col4\" class=\"data row7 col4\" >0.5577</td>\n",
       "      <td id=\"T_6d425_row7_col5\" class=\"data row7 col5\" >0.1551</td>\n",
       "      <td id=\"T_6d425_row7_col6\" class=\"data row7 col6\" >0.2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6d425_row8_col0\" class=\"data row8 col0\" >0.6571</td>\n",
       "      <td id=\"T_6d425_row8_col1\" class=\"data row8 col1\" >0.6454</td>\n",
       "      <td id=\"T_6d425_row8_col2\" class=\"data row8 col2\" >0.6571</td>\n",
       "      <td id=\"T_6d425_row8_col3\" class=\"data row8 col3\" >0.5083</td>\n",
       "      <td id=\"T_6d425_row8_col4\" class=\"data row8 col4\" >0.5544</td>\n",
       "      <td id=\"T_6d425_row8_col5\" class=\"data row8 col5\" >0.1551</td>\n",
       "      <td id=\"T_6d425_row8_col6\" class=\"data row8 col6\" >0.2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6d425_row9_col0\" class=\"data row9 col0\" >0.6743</td>\n",
       "      <td id=\"T_6d425_row9_col1\" class=\"data row9 col1\" >0.6757</td>\n",
       "      <td id=\"T_6d425_row9_col2\" class=\"data row9 col2\" >0.6743</td>\n",
       "      <td id=\"T_6d425_row9_col3\" class=\"data row9 col3\" >0.5309</td>\n",
       "      <td id=\"T_6d425_row9_col4\" class=\"data row9 col4\" >0.5882</td>\n",
       "      <td id=\"T_6d425_row9_col5\" class=\"data row9 col5\" >0.2465</td>\n",
       "      <td id=\"T_6d425_row9_col6\" class=\"data row9 col6\" >0.3048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_6d425_row10_col0\" class=\"data row10 col0\" >0.6726</td>\n",
       "      <td id=\"T_6d425_row10_col1\" class=\"data row10 col1\" >0.6946</td>\n",
       "      <td id=\"T_6d425_row10_col2\" class=\"data row10 col2\" >0.6726</td>\n",
       "      <td id=\"T_6d425_row10_col3\" class=\"data row10 col3\" >0.5508</td>\n",
       "      <td id=\"T_6d425_row10_col4\" class=\"data row10 col4\" >0.5780</td>\n",
       "      <td id=\"T_6d425_row10_col5\" class=\"data row10 col5\" >0.2041</td>\n",
       "      <td id=\"T_6d425_row10_col6\" class=\"data row10 col6\" >0.2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d425_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_6d425_row11_col0\" class=\"data row11 col0\" >0.0166</td>\n",
       "      <td id=\"T_6d425_row11_col1\" class=\"data row11 col1\" >0.0381</td>\n",
       "      <td id=\"T_6d425_row11_col2\" class=\"data row11 col2\" >0.0166</td>\n",
       "      <td id=\"T_6d425_row11_col3\" class=\"data row11 col3\" >0.0698</td>\n",
       "      <td id=\"T_6d425_row11_col4\" class=\"data row11 col4\" >0.0195</td>\n",
       "      <td id=\"T_6d425_row11_col5\" class=\"data row11 col5\" >0.0461</td>\n",
       "      <td id=\"T_6d425_row11_col6\" class=\"data row11 col6\" >0.0568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22e356e7bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-05 19:56:31,445] Searching the best hyperparameters using 1750 samples...\n",
      "[I 2024-01-05 19:57:14,990] Finished hyperparameter search!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion=&#x27;gini&#x27;, max_depth=None, max_features=&#x27;sqrt&#x27;,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                       random_state=777, verbose=0, warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion=&#x27;gini&#x27;, max_depth=None, max_features=&#x27;sqrt&#x27;,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                       random_state=777, verbose=0, warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                       random_state=777, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_model(myrf,search_library='optuna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "\n'skopt' is a soft dependency and not included in the pycaret installation. Please run: `pip install scikit-optimize` to install.\nAlternately, you can install this by running `pip install pycaret[tuners]`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8600\\4142665708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtune_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyrf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msearch_library\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'scikit-optimize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pycaret\\utils\\generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mglobals_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pycaret\\classification\\functional.py\u001b[0m in \u001b[0;36mtune_model\u001b[1;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \"\"\"\n\u001b[0;32m   1207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m     return _CURRENT_EXPERIMENT.tune_model(\n\u001b[0m\u001b[0;32m   1209\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m         \u001b[0mfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pycaret\\classification\\oop.py\u001b[0m in \u001b[0;36mtune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \"\"\"\n\u001b[0;32m   1557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1558\u001b[1;33m         return super().tune_model(\n\u001b[0m\u001b[0;32m   1559\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m             \u001b[0mfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py\u001b[0m in \u001b[0;36mtune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   2050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2051\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msearch_library\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"scikit-optimize\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2052\u001b[1;33m             _check_soft_dependencies(\n\u001b[0m\u001b[0;32m   2053\u001b[0m                 \u001b[1;34m\"skopt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2054\u001b[0m                 \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tuners\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pycaret\\utils\\_dependencies.py\u001b[0m in \u001b[0;36m_check_soft_dependencies\u001b[1;34m(package, severity, extra, install_name)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mseverity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"error\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{msg}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mseverity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"warning\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{msg}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: \n'skopt' is a soft dependency and not included in the pycaret installation. Please run: `pip install scikit-optimize` to install.\nAlternately, you can install this by running `pip install pycaret[tuners]`"
     ]
    }
   ],
   "source": [
    "tune_model(myrf,search_library='scikit-optimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00899141, 0.01167563, 0.01146716, 0.01199454, 0.01015189,\n",
       "       0.01139968, 0.00699235, 0.01021861, 0.00995055, 0.01139708,\n",
       "       0.02804846, 0.01079435, 0.01775243, 0.01351114, 0.0063249 ,\n",
       "       0.0117027 , 0.0169328 , 0.01011632, 0.020521  , 0.00879552,\n",
       "       0.01224404, 0.02534318, 0.00860571, 0.02912868, 0.012921  ,\n",
       "       0.01264667, 0.01301727, 0.01015482, 0.00626466, 0.01535021,\n",
       "       0.02312508, 0.0230009 , 0.0221243 , 0.01419124, 0.01187053,\n",
       "       0.01797068, 0.02322524, 0.01677234, 0.01875758, 0.01056436,\n",
       "       0.018808  , 0.02485622, 0.00723575, 0.00682452, 0.00700659,\n",
       "       0.01105585, 0.01155798, 0.01101428, 0.02792741, 0.01770357,\n",
       "       0.04058669, 0.00923058, 0.01184148, 0.00888503, 0.04248482,\n",
       "       0.01296083, 0.00938104, 0.00718902, 0.01079016, 0.01346259,\n",
       "       0.01278845, 0.01042443, 0.00776008, 0.01159133, 0.01573239,\n",
       "       0.03777537, 0.01710854])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.042485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.040587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.037775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.029129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.028048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>0.007007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.006992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "      <td>0.006825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>been</th>\n",
       "      <td>0.006325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours</th>\n",
       "      <td>0.006265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Importance\n",
       "to       0.042485\n",
       "the      0.040587\n",
       "you      0.037775\n",
       "for      0.029129\n",
       "and      0.028048\n",
       "...           ...\n",
       "plane    0.007007\n",
       "all      0.006992\n",
       "out      0.006825\n",
       "been     0.006325\n",
       "hours    0.006265\n",
       "\n",
       "[67 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tuned_model.feature_importances_, index=X.columns[:X.shape[1]-1],columns=['Importance']).sort_values('Importance',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any decision tree based ensemble model give feature importance\n",
    "# Random Forest, Adaboost, Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class=&#x27;auto&#x27;,\n",
       "                                                 n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                 random_state=None,\n",
       "                                                 solver=&#x27;lbfgs&#x27;, tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             (&#x27;sv&#x27;,\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             (&#x27;dt&#x27;,\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion=&#x27;gini&#x27;,\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter=&#x27;best&#x27;))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting=&#x27;hard&#x27;, weights=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class=&#x27;auto&#x27;,\n",
       "                                                 n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                 random_state=None,\n",
       "                                                 solver=&#x27;lbfgs&#x27;, tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             (&#x27;sv&#x27;,\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             (&#x27;dt&#x27;,\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion=&#x27;gini&#x27;,\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter=&#x27;best&#x27;))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting=&#x27;hard&#x27;, weights=None)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sv</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('sv',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting='hard', weights=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine Heterogeneous Models - Hard voting\n",
    "\n",
    "from sklearn.ensemble import  VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import  SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "inp = X.drop('output',axis=1)\n",
    "output = X['output']\n",
    "x_train,x_test,y_train,y_test = train_test_split(inp,output,test_size = 0.3)\n",
    "mymodels =  [('lr',LogisticRegression()),('sv',SVC(probability = True)),('dt',DecisionTreeClassifier())]\n",
    "\n",
    "vc = VotingClassifier(mymodels, voting = 'hard')\n",
    "vc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'positive', 'neutral', 'negative',\n",
       "       'negative', 'negative', 'negative', 'neutral', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'neutral', 'negative', 'negative', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'neutral', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'neutral',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'neutral', 'negative',\n",
       "       'negative', 'neutral', 'positive', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.predict(x_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6973333333333334"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import  accuracy_score\n",
    "accuracy_score(y_test,vc.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class=&#x27;auto&#x27;,\n",
       "                                                 n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                 random_state=None,\n",
       "                                                 solver=&#x27;lbfgs&#x27;, tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             (&#x27;sv&#x27;,\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             (&#x27;dt&#x27;,\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion=&#x27;gini&#x27;,\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter=&#x27;best&#x27;))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting=&#x27;soft&#x27;, weights=[0.3, 0.5, 0.2])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;,\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class=&#x27;auto&#x27;,\n",
       "                                                 n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                                                 random_state=None,\n",
       "                                                 solver=&#x27;lbfgs&#x27;, tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             (&#x27;sv&#x27;,\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             (&#x27;dt&#x27;,\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion=&#x27;gini&#x27;,\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter=&#x27;best&#x27;))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting=&#x27;soft&#x27;, weights=[0.3, 0.5, 0.2])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sv</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('sv',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  de...\n",
       "                                  shrinking=True, tol=0.001, verbose=False)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting='soft', weights=[0.3, 0.5, 0.2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine Heterogeneous Models - soft voting\n",
    "inp = X.drop('output',axis=1)\n",
    "output = X['output'].map({\"positive\" : 1, \"negative\" : 2, \"neutral\" : 0})\n",
    "x_train,x_test,y_train,y_test = train_test_split(inp,output,test_size = 0.3)\n",
    "mymodels =  [('lr',LogisticRegression()),('sv',SVC(probability = True)),('dt',DecisionTreeClassifier())]\n",
    "\n",
    "vc = VotingClassifier(mymodels, voting = 'soft',weights=[0.3,0.5,0.2])\n",
    "vc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.708"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,vc.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0,\n",
       "       0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 2, 0,\n",
       "       2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       1, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,\n",
       "       0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 2, 2, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       1, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 0, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2,\n",
       "       2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 1, 2, 0,\n",
       "       2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.estimators_[1].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6946666666666667"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,vc.estimators_[1].predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826666666666666"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,vc.estimators_[0].predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6013333333333334"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,vc.estimators_[2].predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
